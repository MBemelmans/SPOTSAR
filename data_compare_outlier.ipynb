{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import external packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numba\n",
    "from numba import vectorize\n",
    "import glob # for file search\n",
    "import copy\n",
    "import os # operating system stuff\n",
    "import re # regex\n",
    "import fastparquet # fast read/write for large data structures\n",
    "import sklearn.preprocessing as pre # for data normalisation\n",
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "import geopandas as gpd\n",
    "import rasterio as rio\n",
    "import rasterio.mask\n",
    "from rasterio.plot import plotting_extent\n",
    "from shapely.geometry import Polygon\n",
    "from shapely.geometry.point import Point\n",
    "import pyproj\n",
    "from pyproj import CRS\n",
    "from inpoly import inpoly2 # for fast inpolygon checks\n",
    "import utm\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "import matplotlib.dates as mdates\n",
    "from matplotlib import cm as mpl_cm\n",
    "from matplotlib import colors as mcolors \n",
    "\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable # for colorbar scaling\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "from matplotlib_scalebar.scalebar import ScaleBar\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "\n",
    "import seaborn as sns\n",
    "from matplotlib import rc_file_defaults\n",
    "rc_file_defaults()\n",
    "# sns.set(style=None, color_codes=True)\n",
    "\n",
    "from shapely.geometry import Polygon\n",
    "from shapely.geometry.point import Point\n",
    "import datetime\n",
    "\n",
    "import configparser\n",
    "\n",
    "from cmcrameri import cm # for scientific colourmaps\n",
    "\n",
    "###########################\n",
    "# import main local package\n",
    "import SPOTSAR_main as sm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "################ Define user INPUTS #######################\n",
    "######## please edit the values of this block only ########\n",
    "###########################################################\n",
    "\n",
    "# define hillshade file\n",
    "HS_FILE = './test_data/DEM/TDX_Merapi_WGS84_HS.tif'\n",
    "\n",
    "# define lon and lat files\n",
    "LON_FILE = './test_data/CSK_dsc/geo2/20200910.lon'\n",
    "LAT_FILE = './test_data/CSK_dsc/geo2/20200910.lat'\n",
    "\n",
    "# define parameter text file\n",
    "PARAM_FILE = './test_data/CSK_dsc/params.txt'\n",
    "\n",
    "# define map region of interest\n",
    "lon_lims = [110.425, 110.45]\n",
    "lat_lims = [-7.555, -7.535]\n",
    "\n",
    "# define colour range {min max} (min = -max)\n",
    "vmax = 3 # range of colourscale in meters\n",
    "\n",
    "# define file names for data, lon and lat\n",
    "DIRECTORY_PATH = \"./test_data/CSK_dsc/DISP_txt2/\"\n",
    "# define path to ccp and ccs files\n",
    "DIRECTORY_PATH_CCS = \"./test_data/CSK_dsc/CCS2/\"\n",
    "\n",
    "# Set the regular expression pattern to match the file names\n",
    "PATTERN1 = r\"^c20200927_c20201113_disp_[0-9]+_[0-9]+\\.txt$\"\n",
    "PATTERN2 = r\"^c20200926_c20201113_disp_[0-9]+_[0-9]+\\.txt$\"\n",
    "PATTERN3 = r\"^c20200927_c20210812_disp_[0-9]+_[0-9]+\\.txt$\"\n",
    "PATTERN4 = r\"^c20210217_c20210218_disp_[0-9]+_[0-9]+\\.txt$\"\n",
    "\n",
    "# Set the regular expression pattern to match the ccs file names\n",
    "PATTERN_CCS1 = r\"^c20200927_c20201113_ccs_[0-9]+_[0-9]+$\"\n",
    "PATTERN_CCS2 = r\"^c20200926_c20201113_ccs_[0-9]+_[0-9]+$\"\n",
    "PATTERN_CCS3 = r\"^c20200927_c20210812_ccs_[0-9]+_[0-9]+$\"\n",
    "PATTERN_CCS4 = r\"^c20210217_c20210218_ccs_[0-9]+_[0-9]+$\"\n",
    "\n",
    "\n",
    "# open hillshade file and re-order offset and CCS files\n",
    "\n",
    "# open hill shade file with rasterio\n",
    "DEM_HS = rio.open(HS_FILE)\n",
    "SHADING = DEM_HS.read(1,masked=True) # rasterio bands are indexed from 1\n",
    "\n",
    "# extract DEM extent\n",
    "DEM_EXTENT=[DEM_HS.bounds.left,DEM_HS.bounds.right,DEM_HS.bounds.bottom,DEM_HS.bounds.top]\n",
    "\n",
    "# read parameters from text file\n",
    "config = configparser.ConfigParser()\n",
    "config.read(PARAM_FILE)\n",
    "WIDTH = int(config.get('params', 'width'))\n",
    "LINES = int(config.get('params', 'lines'))\n",
    "WIDTH_CCS = int(config.get('params', 'width_ccs'))\n",
    "LINES_CCS = int(config.get('params', 'lines_ccs'))\n",
    "R_START = int(config.get('params', 'r_start'))\n",
    "A_START = int(config.get('params', 'a_start'))\n",
    "R_STEP = int(config.get('params', 'r_step'))\n",
    "A_STEP = int(config.get('params', 'a_step'))\n",
    "HEADING = float(config.get('params', 'heading'))\n",
    "MEAN_INC = float(config.get('params', 'mean_inc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['c20200927_c20201113_disp_58_28.txt', 'c20200927_c20201113_disp_140_68.txt', 'c20200927_c20201113_disp_224_108.txt', 'c20200927_c20201113_disp_306_148.txt', 'c20200927_c20201113_disp_388_188.txt']\n",
      "['c20200927_c20201113_ccs_58_28', 'c20200927_c20201113_ccs_140_68', 'c20200927_c20201113_ccs_224_108', 'c20200927_c20201113_ccs_306_148', 'c20200927_c20201113_ccs_388_188']\n",
      "['c20200926_c20201113_disp_58_28.txt', 'c20200926_c20201113_disp_140_68.txt', 'c20200926_c20201113_disp_224_108.txt', 'c20200926_c20201113_disp_306_148.txt', 'c20200926_c20201113_disp_388_188.txt']\n",
      "['c20200926_c20201113_ccs_58_28', 'c20200926_c20201113_ccs_140_68', 'c20200926_c20201113_ccs_224_108', 'c20200926_c20201113_ccs_306_148', 'c20200926_c20201113_ccs_388_188']\n",
      "['c20200927_c20210812_disp_58_28.txt', 'c20200927_c20210812_disp_140_68.txt', 'c20200927_c20210812_disp_224_108.txt', 'c20200927_c20210812_disp_306_148.txt', 'c20200927_c20210812_disp_388_188.txt']\n",
      "['c20200927_c20210812_ccs_58_28', 'c20200927_c20210812_ccs_140_68', 'c20200927_c20210812_ccs_224_108', 'c20200927_c20210812_ccs_306_148', 'c20200927_c20210812_ccs_388_188']\n",
      "['c20210217_c20210218_disp_58_28.txt', 'c20210217_c20210218_disp_140_68.txt', 'c20210217_c20210218_disp_224_108.txt', 'c20210217_c20210218_disp_306_148.txt', 'c20210217_c20210218_disp_388_188.txt']\n",
      "['c20210217_c20210218_ccs_58_28', 'c20210217_c20210218_ccs_140_68', 'c20210217_c20210218_ccs_224_108', 'c20210217_c20210218_ccs_306_148', 'c20210217_c20210218_ccs_388_188']\n",
      "['c20210217_c20210218_disp_58_28.txt', 'c20210217_c20210218_disp_99_48.txt', 'c20210217_c20210218_disp_140_68.txt', 'c20210217_c20210218_disp_182_88.txt', 'c20210217_c20210218_disp_224_108.txt']\n",
      "['c20210217_c20210218_ccs_58_28', 'c20210217_c20210218_ccs_99_48', 'c20210217_c20210218_ccs_140_68', 'c20210217_c20210218_ccs_182_88', 'c20210217_c20210218_ccs_224_108']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# reorder file using Post_processing.reorder_files\n",
    "matching_files1 = sm.Post_processing.reorder_files(DIRECTORY_PATH,PATTERN1,0)\n",
    "matching_files_ccs1 = sm.Post_processing.reorder_files(DIRECTORY_PATH_CCS,PATTERN_CCS1,0)\n",
    "matching_files2 = sm.Post_processing.reorder_files(DIRECTORY_PATH,PATTERN2,0)\n",
    "matching_files_ccs2 = sm.Post_processing.reorder_files(DIRECTORY_PATH_CCS,PATTERN_CCS2,0)\n",
    "matching_files3 = sm.Post_processing.reorder_files(DIRECTORY_PATH,PATTERN3,0)\n",
    "matching_files_ccs3 = sm.Post_processing.reorder_files(DIRECTORY_PATH_CCS,PATTERN_CCS3,0)\n",
    "matching_files4 = sm.Post_processing.reorder_files(DIRECTORY_PATH,PATTERN4,0)\n",
    "matching_files_ccs4 = sm.Post_processing.reorder_files(DIRECTORY_PATH_CCS,PATTERN_CCS4,0)\n",
    "matching_files5 = sm.Post_processing.reorder_files(DIRECTORY_PATH+'stor/',PATTERN4,0)\n",
    "matching_files_ccs5 = sm.Post_processing.reorder_files(DIRECTORY_PATH_CCS+'stor/',PATTERN_CCS4,0)\n",
    "\n",
    "\n",
    "# test if file ordering has worked\n",
    "print(matching_files1)\n",
    "print(matching_files_ccs1)\n",
    "print(matching_files2)\n",
    "print(matching_files_ccs2)\n",
    "print(matching_files3)\n",
    "print(matching_files_ccs3)\n",
    "print(matching_files4)\n",
    "print(matching_files_ccs4)\n",
    "print(matching_files5)\n",
    "print(matching_files_ccs5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# load data from files into class multi-kernel\n",
    "example_pairs = []\n",
    "i = 0\n",
    "for (matching_files,matching_files_ccs) in zip([matching_files1,matching_files2,matching_files3,matching_files4,matching_files5],[matching_files_ccs1,matching_files_ccs2,matching_files_ccs3,matching_files_ccs4,matching_files_ccs5]):\n",
    "    if i==4:\n",
    "        datastack = sm.Post_processing.MultiKernel(DIRECTORY_PATH+'stor/',\n",
    "                                                matching_files,\n",
    "                                                DIRECTORY_PATH_CCS+'stor/',\n",
    "                                                matching_files_ccs,\n",
    "                                                LAT_FILE,\n",
    "                                                LON_FILE,\n",
    "                                                HEADING,\n",
    "                                                MEAN_INC,\n",
    "                                                LINES_CCS,\n",
    "                                                WIDTH_CCS)\n",
    "    else:\n",
    "        datastack = sm.Post_processing.MultiKernel(DIRECTORY_PATH,\n",
    "                                                matching_files,\n",
    "                                                DIRECTORY_PATH_CCS,\n",
    "                                                matching_files_ccs,\n",
    "                                                LAT_FILE,\n",
    "                                                LON_FILE,\n",
    "                                                HEADING,\n",
    "                                                MEAN_INC,\n",
    "                                                LINES_CCS,\n",
    "                                                WIDTH_CCS)\n",
    "\n",
    "    # We need to assign some data not stored in the disp.txt files.\n",
    "    datastack.get_params_from_file_name()\n",
    "    datastack.get_latlon_from_file(WIDTH)\n",
    "    datastack.add_lat_lon_to_data(R_START,A_START)\n",
    "    datastack.crop_stack_ccs(R_STEP,A_STEP)\n",
    "    # the object datastack now has several attributes associated with the whole dataset (e.g., date1, date2, heading)\n",
    "    # Next we add all the offset data (disp.txt) to the stack\n",
    "    stacked_data = datastack.assign_data_to_stack(R_STEP,A_STEP)\n",
    "    # The attribute 'Stack' we find a list of single-kernel objects which contain the actual offset data, ccp and ccs data and the coordinates.\n",
    "\n",
    "    # add stack to list\n",
    "    example_pairs.append(datastack)\n",
    "    i +=1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib osx\n",
    "# from scipy.ndimage import generic_filter\n",
    "# from skimage.morphology import disk\n",
    "# from skimage import filters\n",
    "# from scipy.spatial import cKDTree\n",
    "\n",
    "# filt_size = 3\n",
    "# filt_radius = 3\n",
    "# footprint = disk(radius=filt_radius)\n",
    "# pre_R_non_veg_list = []\n",
    "# pre_R_veg_list = []\n",
    "# pre_A_non_veg_list = []\n",
    "# pre_A_veg_list = []\n",
    "\n",
    "# for obj in example_pairs[3].Stack:\n",
    "#     R_off = obj.R_off\n",
    "#     A_off = obj.A_off\n",
    "\n",
    "#     print('starting filters')\n",
    "\n",
    "#     R_off_std = generic_filter(R_off, np.nanstd, footprint=footprint)\n",
    "#     A_off_std = generic_filter(A_off, np.nanstd, footprint=footprint)\n",
    "\n",
    "#     print('filters done')\n",
    "\n",
    "\n",
    "#     DEM_lon_lat = np.column_stack((DEM_lons.flatten(),DEM_lats.flatten()))\n",
    "#     NDVI_lon_lat = np.column_stack((NDVI_lons.flatten(),NDVI_lats.flatten()))\n",
    "#     data_lon_lat = np.column_stack((obj.Lon_off.flatten(),obj.Lat_off.flatten()))\n",
    "\n",
    "#     print('build trees')\n",
    "#     kdtree_dem = cKDTree(DEM_lon_lat)\n",
    "#     kdtree_ndvi = cKDTree(NDVI_lon_lat)\n",
    "#     print('done building trees')\n",
    "\n",
    "#     data_dem = np.empty(np.shape(R_off.flatten()))\n",
    "#     data_slope = np.empty(np.shape(R_off.flatten()))\n",
    "#     data_ndvi = np.empty(np.shape(R_off.flatten()))\n",
    "#     idx_list = []\n",
    "#     for i, point in enumerate(data_lon_lat):\n",
    "#         if not all(np.isnan(point)):\n",
    "#             print(i)\n",
    "#             distance,index_DEM = kdtree_dem.query(point)\n",
    "#             distance,index_NDVI = kdtree_ndvi.query(point)\n",
    "#             idx_list.append([i,index_DEM,index_NDVI])\n",
    "\n",
    "#     idx_list = np.asarray(idx_list)\n",
    "#     data_dem[idx_list[:,0]] = DEM_heights.flatten()[idx_list[:,1]]\n",
    "#     data_slope[idx_list[:,0]] = DEM_slope.flatten()[idx_list[:,1]]\n",
    "#     data_ndvi[idx_list[:,0]] = NDVI.flatten()[idx_list[:,2]]\n",
    "#     data_ndvi[data_ndvi<-1] = np.nan\n",
    "\n",
    "#     R_sel_non_veg = R_off_std.flatten()[np.argwhere(np.abs(data_ndvi) <= 0.1)]\n",
    "#     A_sel_non_veg = A_off_std.flatten()[np.argwhere(np.abs(data_ndvi) <= 0.1)]\n",
    "#     R_sel_veg = R_off_std.flatten()[np.argwhere(data_ndvi >= 0.5)]\n",
    "#     A_sel_veg = A_off_std.flatten()[np.argwhere(data_ndvi >= 0.5)]\n",
    "\n",
    "#     R_data_non_veg = R_sel_non_veg.flatten()\n",
    "#     R_data_veg = R_sel_veg.flatten()\n",
    "#     R_data_non_veg[R_data_non_veg <= 0] = np.nan\n",
    "#     R_data_veg[R_data_veg <= 0] = np.nan\n",
    "#     A_data_non_veg = A_sel_non_veg.flatten()\n",
    "#     A_data_veg = A_sel_veg.flatten()\n",
    "#     A_data_non_veg[A_data_non_veg <= 0] = np.nan\n",
    "#     A_data_veg[A_data_veg <= 0] = np.nan\n",
    "\n",
    "#     pre_R_non_veg_list.append(R_data_non_veg)\n",
    "#     pre_R_veg_list.append(R_data_veg)\n",
    "#     pre_A_non_veg_list.append(A_data_non_veg)\n",
    "#     pre_A_veg_list.append(A_data_veg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load med filt and MKA results from h5 files\n",
    "\n",
    "import h5py \n",
    "\n",
    "# file1 contains window sizes 58, 140, 224, 306, 388, MKA 1-5, MKA 1-3\n",
    "file1 = './test_data/CSK_dsc/filtered_MKA_offsets/c20200927_c20201113_v3.h5'\n",
    "\n",
    "\n",
    "# provide attribute names\n",
    "attr_names1 = ['win_1_Lon', 'win_1_lat', 'win_1_R_off', 'win_1_A_off',\n",
    "               'win_2_Lon', 'win_2_lat', 'win_2_R_off', 'win_2_A_off',\n",
    "               'win_3_Lon', 'win_3_lat', 'win_3_R_off', 'win_3_A_off',\n",
    "               'win_4_Lon', 'win_4_lat', 'win_4_R_off', 'win_4_A_off',\n",
    "               'win_5_Lon', 'win_5_lat', 'win_5_R_off', 'win_5_A_off',\n",
    "               'win_13_Lon', 'win_13_lat', 'win_13_R_off', 'win_13_A_off',\n",
    "               'win_15_Lon', 'win_15_lat', 'win_15_R_off', 'win_15_A_off',]\n",
    "\n",
    "\n",
    "\n",
    "obj1 = example_pairs[0]\n",
    "\n",
    "for i, (file, obj,attr_names) in enumerate(zip([file1],[obj1],[attr_names1])):\n",
    "    f = h5py.File(file,'r')\n",
    "    for qkey in attr_names:\n",
    "        attr = np.array(f[f'{qkey}'][:])\n",
    "        # attr = f.get(f'{qkey}')\n",
    "        setattr(obj,f'{qkey}',attr)\n",
    "    f.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A_win', 'Ccs_maps', 'Data', 'Data_ccs', 'Date1', 'Date2', 'Filenames', 'Filenames_ccs', 'Heading', 'Lat', 'Lat_file', 'Lat_vec', 'Limits', 'Lon', 'Lon_file', 'Lon_vec', 'Mask_data', 'Mask_data_ccs', 'Mean_inc', 'R_win', 'Run_MKA', 'Run_RSS', 'Stack', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', 'add_lat_lon_to_data', 'assign_data_to_stack', 'crop_stack_ccs', 'get_latlon_from_file', 'get_params_from_file_name', 'outlier_detection_HDBSCAN_stack', 'outlier_detection_LOF_stack', 'outlier_detection_median_stack', 'query_point_MKA', 'query_point_stack', 'win_13_A_off', 'win_13_Lon', 'win_13_R_off', 'win_13_lat', 'win_15_A_off', 'win_15_Lon', 'win_15_R_off', 'win_15_lat', 'win_1_A_off', 'win_1_Lon', 'win_1_R_off', 'win_1_lat', 'win_2_A_off', 'win_2_Lon', 'win_2_R_off', 'win_2_lat', 'win_3_A_off', 'win_3_Lon', 'win_3_R_off', 'win_3_lat', 'win_4_A_off', 'win_4_Lon', 'win_4_R_off', 'win_4_lat', 'win_5_A_off', 'win_5_Lon', 'win_5_R_off', 'win_5_lat']\n"
     ]
    }
   ],
   "source": [
    "print(dir(obj1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Band1 has shape (2028, 1672)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Band1 has shape (171, 141)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/m9/32v45xkn4zx6js6htb1prb2r0000gn/T/ipykernel_79289/3334344435.py:65: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
      "  x= mpl_cm.get_cmap('Blues_r', 135)\n",
      "/var/folders/m9/32v45xkn4zx6js6htb1prb2r0000gn/T/ipykernel_79289/3334344435.py:66: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
      "  y= mpl_cm.get_cmap('YlGn', 135)\n"
     ]
    }
   ],
   "source": [
    "# load external data\n",
    "\n",
    "import fiona\n",
    "from matplotlib.colors import ListedColormap\n",
    "from matplotlib import cm as mpl_cm\n",
    "## find nearest elevation, slope, and NDVI values\n",
    "DEM_FILE = './test_data/DEM/TDX_Merapi_WGS84_5m.tif'\n",
    "SLOPE_FILE = './test_data/DEM/TDX_Merapi_WGS84_5m_slope.tif'\n",
    "NDVI_FILE = '/Users/markbemelmans/Documents/PhD/projects/Merapi2021/sentinel2/Sentinel_NDVI_WGS84_v2.tif'\n",
    "\n",
    "with rio.open(DEM_FILE) as src:\n",
    "    DEM_heights = src.read(1)\n",
    "    print('Band1 has shape', DEM_heights.shape)\n",
    "    height = DEM_heights.shape[0]\n",
    "    width = DEM_heights.shape[1]\n",
    "    cols, rows = np.meshgrid(np.arange(width), np.arange(height))\n",
    "    xs, ys = rio.transform.xy(src.transform, rows, cols)\n",
    "    DEM_lons = np.array(xs)\n",
    "    DEM_lats = np.array(ys)\n",
    "    DEM_extent = [src.bounds.left,src.bounds.right,src.bounds.bottom,src.bounds.top]\n",
    "\n",
    "with rio.open(SLOPE_FILE) as src:\n",
    "    DEM_slope = src.read(1)\n",
    "\n",
    "\n",
    "# define map region of interest\n",
    "lon_lims = [np.nanmin(DEM_lons), np.nanmax(DEM_lons)]\n",
    "lat_lims = [np.nanmin(DEM_lats), np.nanmax(DEM_lats)]\n",
    "crop_flag=1\n",
    "\n",
    "# create cropping polygon from ROI\n",
    "if crop_flag:\n",
    "    coords = ((lon_lims[0], lat_lims[0]), (lon_lims[0], lat_lims[1]), (lon_lims[1], lat_lims[1]), (lon_lims[1], lat_lims[0]), (lon_lims[0], lat_lims[0]))\n",
    "    crop_poly = Polygon(coords)\n",
    "    crop_poly_geojson = gpd.GeoSeries([crop_poly])\n",
    "    crop_poly_geojson.to_file('./test_data/crop_ndvi_poly_v2.shp',crs=\"EPSG:4326\")\n",
    "\n",
    "\n",
    "with fiona.open('./test_data/crop_ndvi_poly_v2.shp', \"r\") as shapefile:\n",
    "    shapes = [feature[\"geometry\"] for feature in shapefile]\n",
    "\n",
    "# get data and read coords from first file\n",
    "with rio.open(NDVI_FILE) as src:\n",
    "    out_image, out_transform = rasterio.mask.mask(src, shapes, crop=True)\n",
    "    out_meta = src.meta\n",
    "    out_meta.update({\"driver\": \"GTiff\",\n",
    "                 \"height\": out_image.shape[1],\n",
    "                 \"width\": out_image.shape[2],\n",
    "                 \"transform\": out_transform})\n",
    "with rasterio.open(\"./test_Data/ndvi_cropped.tif\", \"w\", **out_meta) as dest:\n",
    "    dest.write(out_image)\n",
    "\n",
    "with rio.open(\"./test_Data/ndvi_cropped.tif\") as src:\n",
    "    NDVI = src.read(1)\n",
    "    print('Band1 has shape', NDVI.shape)\n",
    "    height = NDVI.shape[0]\n",
    "    width = NDVI.shape[1]\n",
    "    cols, rows = np.meshgrid(np.arange(width), np.arange(height))\n",
    "    xs, ys = rio.transform.xy(src.transform, rows, cols)\n",
    "    NDVI_lons = np.array(xs)\n",
    "    NDVI_lats = np.array(ys)\n",
    "    NDVI_extent = [src.bounds.left,src.bounds.right,src.bounds.bottom,src.bounds.top]\n",
    "\n",
    "# define colormaps\n",
    "x= mpl_cm.get_cmap('Blues_r', 135)\n",
    "y= mpl_cm.get_cmap('YlGn', 135)\n",
    "z = np.vstack((x(range(135)),\n",
    "                       y(range(135))))\n",
    "ndvi_cmap = ListedColormap(z, name='BlYlGn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# lava flow files:\n",
    "L1888_FILE = '/Users/markbemelmans/Documents/PhD/projects/Merapi2021/merapi_maps/L1888_v2.shp'\n",
    "L1948_FILE = '/Users/markbemelmans/Documents/PhD/projects/Merapi2021/merapi_maps/L1948.shp'\n",
    "L1956_FILE = '/Users/markbemelmans/Documents/PhD/projects/Merapi2021/merapi_maps/L1956.shp'\n",
    "L1992_FILE = '/Users/markbemelmans/Documents/PhD/projects/Merapi2021/merapi_maps/L1992.shp'\n",
    "L1997_FILE = '/Users/markbemelmans/Documents/PhD/projects/Merapi2021/merapi_maps/L1997.shp'\n",
    "L1998_FILE = '/Users/markbemelmans/Documents/PhD/projects/Merapi2021/merapi_maps/L1998.shp'\n",
    "CRATER_FILE = '/Users/markbemelmans/Documents/PhD/projects/Merapi2021/merapi_maps/Merapi_crater.shp'\n",
    "\n",
    "# Read the shapefile\n",
    "L1888 = gpd.read_file(L1888_FILE)\n",
    "L1948 = gpd.read_file(L1948_FILE)\n",
    "L1956 = gpd.read_file(L1956_FILE)\n",
    "L1992 = gpd.read_file(L1992_FILE)\n",
    "L1997 = gpd.read_file(L1997_FILE)\n",
    "L1998 = gpd.read_file(L1998_FILE)\n",
    "CRATER = gpd.read_file(CRATER_FILE)\n",
    "\n",
    "# Extract latitude and longitude into separate columns\n",
    "coords_L1888 = np.array(list(L1888[\"geometry\"][0].coords))\n",
    "coords_L1956_1 = np.array(list(L1956[\"geometry\"][0].coords))\n",
    "coords_L1956_2 = np.array(list(L1956[\"geometry\"][1].coords))\n",
    "coords_L1948 = np.array(list(L1948[\"geometry\"][0].coords))\n",
    "coords_L1992 = np.array(list(L1992[\"geometry\"][0].coords))\n",
    "coords_L1997 = np.array(list(L1997[\"geometry\"][0].coords))\n",
    "coords_L1998 = np.array(list(L1998[\"geometry\"][0].coords))\n",
    "coords_CRATER = np.array(list(CRATER[\"geometry\"][0].coords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "%matplotlib osx\n",
    "\n",
    "import string\n",
    "## plot results before and after outlier removal\n",
    "\n",
    "def plot_offset(ax, Lon_off,Lat_off, arr, grid_size,cmap, clims,lon_lims,lat_lims):\n",
    "    plot_data = ax.hexbin(Lon_off.flatten(),Lat_off.flatten(),C=arr.flatten(),gridsize=grid_size,cmap=cmap,vmin=clims[0],vmax=clims[1])\n",
    "    ax.set_xlim(lon_lims)\n",
    "    ax.set_ylim(lat_lims)\n",
    "    ax.set_aspect('equal', 'box')\n",
    "    ax.add_artist(ScaleBar(sm.plot.get_1deg_dist(),location='lower left'))\n",
    "    return plot_data, ax\n",
    "\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(10,8))\n",
    "gs = GridSpec(5, 4, figure=fig)\n",
    "ax00 = fig.add_subplot(gs[0, 0]) # win 1 R off pre\n",
    "ax10 = fig.add_subplot(gs[1, 0]) # win 2 R off pre\n",
    "ax20 = fig.add_subplot(gs[2, 0]) # win 3 R off pre\n",
    "ax30 = fig.add_subplot(gs[3, 0]) # win 4 R off pre\n",
    "ax40 = fig.add_subplot(gs[4, 0]) # win 5 R off pre\n",
    "\n",
    "ax01 = fig.add_subplot(gs[0, 1]) # win 1 A off pre\n",
    "ax11 = fig.add_subplot(gs[1, 1]) # win 2 A off pre\n",
    "ax21 = fig.add_subplot(gs[2, 1]) # win 3 A off pre\n",
    "ax31 = fig.add_subplot(gs[3, 1]) # win 4 A off pre\n",
    "ax41 = fig.add_subplot(gs[4, 1]) # win 5 A off pre\n",
    "\n",
    "\n",
    "ax02 = fig.add_subplot(gs[0, 2]) # win 1 R off post\n",
    "ax12 = fig.add_subplot(gs[1, 2]) # win 2 R off post\n",
    "ax22 = fig.add_subplot(gs[2, 2]) # win 3 R off post\n",
    "ax32 = fig.add_subplot(gs[3, 2]) # win 4 R off post\n",
    "ax42 = fig.add_subplot(gs[4, 2]) # win 5 R off post\n",
    "\n",
    "ax03 = fig.add_subplot(gs[0, 3]) # win 1 A off post\n",
    "ax13 = fig.add_subplot(gs[1, 3]) # win 2 A off post\n",
    "ax23 = fig.add_subplot(gs[2, 3]) # win 3 A off post\n",
    "ax33 = fig.add_subplot(gs[3, 3]) # win 4 A off post\n",
    "ax43 = fig.add_subplot(gs[4, 3]) # win 5 A off post\n",
    "\n",
    "grid_size = 1000\n",
    "clims = [-3,3]\n",
    "cmap = cm.vik\n",
    "lon_lims = [110.4313, 110.4496]\n",
    "lat_lims = [-7.5463, -7.5350]\n",
    "\n",
    "plot_offset(ax00, obj1.Stack[0].Lon_off,obj1.Stack[0].Lat_off,obj1.Stack[0].R_off, grid_size,cmap, clims,lon_lims,lat_lims)\n",
    "plot_offset(ax10, obj1.Stack[1].Lon_off,obj1.Stack[1].Lat_off,obj1.Stack[1].R_off, grid_size,cmap, clims,lon_lims,lat_lims)\n",
    "plot_offset(ax20, obj1.Stack[2].Lon_off,obj1.Stack[2].Lat_off,obj1.Stack[2].R_off, grid_size,cmap, clims,lon_lims,lat_lims)\n",
    "plot_offset(ax30, obj1.Stack[3].Lon_off,obj1.Stack[3].Lat_off,obj1.Stack[3].R_off, grid_size,cmap, clims,lon_lims,lat_lims)\n",
    "plot_offset(ax40, obj1.Stack[4].Lon_off,obj1.Stack[4].Lat_off,obj1.Stack[4].R_off, grid_size,cmap, clims,lon_lims,lat_lims)\n",
    "\n",
    "plot_offset(ax01, obj1.win_1_Lon,obj1.win_1_lat,obj1.win_1_R_off, grid_size,cmap, clims,lon_lims,lat_lims)\n",
    "plot_offset(ax11, obj1.win_2_Lon,obj1.win_2_lat,obj1.win_2_R_off, grid_size,cmap, clims,lon_lims,lat_lims)\n",
    "plot_offset(ax21, obj1.win_3_Lon,obj1.win_3_lat,obj1.win_3_R_off, grid_size,cmap, clims,lon_lims,lat_lims)\n",
    "plot_offset(ax31, obj1.win_4_Lon,obj1.win_4_lat,obj1.win_4_R_off, grid_size,cmap, clims,lon_lims,lat_lims)\n",
    "plot_offset(ax41, obj1.win_5_Lon,obj1.win_5_lat,obj1.win_5_R_off, grid_size,cmap, clims,lon_lims,lat_lims)\n",
    "\n",
    "\n",
    "plot_offset(ax02, obj1.Stack[0].Lon_off,obj1.Stack[0].Lat_off,obj1.Stack[0].A_off, grid_size,cmap, clims,lon_lims,lat_lims)\n",
    "plot_offset(ax12, obj1.Stack[1].Lon_off,obj1.Stack[1].Lat_off,obj1.Stack[1].A_off, grid_size,cmap, clims,lon_lims,lat_lims)\n",
    "plot_offset(ax22, obj1.Stack[2].Lon_off,obj1.Stack[2].Lat_off,obj1.Stack[2].A_off, grid_size,cmap, clims,lon_lims,lat_lims)\n",
    "plot_offset(ax32, obj1.Stack[3].Lon_off,obj1.Stack[3].Lat_off,obj1.Stack[3].A_off, grid_size,cmap, clims,lon_lims,lat_lims)\n",
    "plot_offset(ax42, obj1.Stack[4].Lon_off,obj1.Stack[4].Lat_off,obj1.Stack[4].A_off, grid_size,cmap, clims,lon_lims,lat_lims)\n",
    "\n",
    "\n",
    "plot_offset(ax03, obj1.win_1_Lon,obj1.win_1_lat,obj1.win_1_A_off, grid_size,cmap, clims,lon_lims,lat_lims)\n",
    "plot_offset(ax13, obj1.win_2_Lon,obj1.win_2_lat,obj1.win_2_A_off, grid_size,cmap, clims,lon_lims,lat_lims)\n",
    "data_for_colourbar = plot_offset(ax23, obj1.win_3_Lon,obj1.win_3_lat,obj1.win_3_A_off, grid_size,cmap, clims,lon_lims,lat_lims)\n",
    "plot_offset(ax33, obj1.win_4_Lon,obj1.win_4_lat,obj1.win_4_A_off, grid_size,cmap, clims,lon_lims,lat_lims)\n",
    "plot_offset(ax43, obj1.win_5_Lon,obj1.win_5_lat,obj1.win_5_A_off, grid_size,cmap, clims,lon_lims,lat_lims)\n",
    "\n",
    "\n",
    "bbox = dict(fc=\"1.0\")\n",
    "for (a, t) in zip(fig.axes,list(string.ascii_uppercase)):\n",
    "    a.get_xaxis().set_visible(False)\n",
    "    # a.get_yaxis().set_visible(False)\n",
    "    a.tick_params(\n",
    "    axis='both',          # changes apply to the x-axis\n",
    "    which='both',      # both major and minor ticks are affected\n",
    "    bottom=False,      # ticks along the bottom edge are off\n",
    "    top=False,         # ticks along the top edge are off\n",
    "    left=False,\n",
    "    right=False,\n",
    "    labelleft=False,\n",
    "    labelbottom=False) # labels along the bottom edge are off\n",
    "    a.annotate(t,xy=(0.03,0.83),xycoords='axes fraction',fontsize=12, bbox=bbox)\n",
    "    a.plot(coords_CRATER[:,0],coords_CRATER[:,1],linewidth=2,color='black',linestyle='--',label='Crater rim')\n",
    "\n",
    "\n",
    "# fig.tight_layout()\n",
    "\n",
    "ax00.set_ylabel('Window size:\\n20 m',fontsize=12)\n",
    "ax10.set_ylabel('Window size:\\n48 m',fontsize=12)\n",
    "ax20.set_ylabel('Window size:\\n75 m',fontsize=12)\n",
    "ax30.set_ylabel('Window size:\\n103 m',fontsize=12)\n",
    "ax40.set_ylabel('Window size:\\n130 m',fontsize=12)\n",
    "\n",
    "ax00.set_title('Original range offset')\n",
    "ax01.set_title('Filtered range offset')\n",
    "ax02.set_title('Original azimuth offset')\n",
    "ax03.set_title('Filtered azimuth offset')\n",
    "\n",
    "# add colourbar axis\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.transforms as mtransforms\n",
    "def add_bottom_cax(ax, pad, width):\n",
    "    axpos = ax.get_position()\n",
    "    caxpos = mtransforms.Bbox.from_extents(\n",
    "        axpos.x0,\n",
    "        axpos.y1-pad-width,\n",
    "        axpos.x1,\n",
    "        axpos.y1-pad\n",
    "    )\n",
    "    cax = ax.figure.add_axes(caxpos)\n",
    "\n",
    "    return cax\n",
    "pad = 0.02\n",
    "width = 0.02\n",
    "ax40_pos = ax40.get_position()\n",
    "ax43_pos = ax43.get_position()\n",
    "caxpos = mtransforms.Bbox.from_extents(\n",
    "    ax40_pos.x0,\n",
    "    ax40_pos.y0-pad-width,\n",
    "    ax43_pos.x1,\n",
    "    ax43_pos.y0-pad\n",
    ")\n",
    "cax = fig.add_axes(caxpos)\n",
    "\n",
    "# cax = add_bottom_cax(ax23, pad=0.02, width=0.02)\n",
    "\n",
    "cbar = fig.colorbar(data_for_colourbar[0], cax=cax,label='Range or azimuth offset [m]', orientation = 'horizontal')\n",
    "cbar.set_label(label='Range or azimuth offset [m]', size=12)\n",
    "fig.subplots_adjust(wspace=0.05, hspace=0.05)\n",
    "fig.savefig('/Users/markbemelmans/Documents/PhD/projects/Merapi2021/figures/outlier_removal_before_after.png',dpi=300)\n",
    "# fig.savefig('/Users/markbemelmans/Documents/PhD/projects/Merapi2021/figures/outlier_removal_before_after.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "plt.close('all')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
