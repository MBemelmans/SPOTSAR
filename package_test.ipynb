{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test to load local package\n",
    "\n",
    "## try on dataset c20200927 c20201113 in folder SPOTSAR/test_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import external packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numba\n",
    "from numba import vectorize\n",
    "import glob # for file search\n",
    "import copy\n",
    "import os # operating system stuff\n",
    "import re # regex\n",
    "import fastparquet # fast read/write for large data structures\n",
    "import sklearn.preprocessing as pre # for data normalisation\n",
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "import geopandas as gpd\n",
    "import rasterio as rio\n",
    "import rasterio.mask\n",
    "from rasterio.plot import plotting_extent\n",
    "from shapely.geometry import Polygon\n",
    "from shapely.geometry.point import Point\n",
    "import pyproj\n",
    "from pyproj import CRS\n",
    "from inpoly import inpoly2 # for fast inpolygon checks\n",
    "import utm\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "import matplotlib.dates as mdates\n",
    "from matplotlib import cm as mpl_cm\n",
    "from matplotlib import colors as mcolors \n",
    "\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable # for colorbar scaling\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "from matplotlib_scalebar.scalebar import ScaleBar\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "\n",
    "import seaborn as sns\n",
    "from matplotlib import rc_file_defaults\n",
    "rc_file_defaults()\n",
    "# sns.set(style=None, color_codes=True)\n",
    "\n",
    "\n",
    "\n",
    "from shapely.geometry import Polygon\n",
    "from shapely.geometry.point import Point\n",
    "import datetime\n",
    "\n",
    "import configparser\n",
    "\n",
    "from cmcrameri import cm # for scientific colourmaps\n",
    "\n",
    "###########################\n",
    "# import main local package\n",
    "import SPOTSAR_main as sm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<module 'glob' from '/Applications/anaconda3/envs/PhD/lib/python3.8/glob.py'>, <module 'rasterio' from '/Applications/anaconda3/envs/PhD/lib/python3.8/site-packages/rasterio/__init__.py'>, <module 'sys' (built-in)>, <module 're' from '/Applications/anaconda3/envs/PhD/lib/python3.8/re.py'>, <module 'os' from '/Applications/anaconda3/envs/PhD/lib/python3.8/os.py'>, <module 'datetime' from '/Applications/anaconda3/envs/PhD/lib/python3.8/datetime.py'>, <module 'fastparquet' from '/Applications/anaconda3/envs/PhD/lib/python3.8/site-packages/fastparquet/__init__.py'>, <module 'copy' from '/Applications/anaconda3/envs/PhD/lib/python3.8/copy.py'>, <module 'numba' from '/Applications/anaconda3/envs/PhD/lib/python3.8/site-packages/numba/__init__.py'>, <module 'pyproj' from '/Applications/anaconda3/envs/PhD/lib/python3.8/site-packages/pyproj/__init__.py'>, <module 'configparser' from '/Applications/anaconda3/envs/PhD/lib/python3.8/configparser.py'>, <module 'utm' from '/Applications/anaconda3/envs/PhD/lib/python3.8/site-packages/utm/__init__.py'>]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "modulenames = set(sys.modules) & set(globals())\n",
    "allmodules = [sys.modules[name] for name in modulenames]\n",
    "print(allmodules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "################ Define user INPUTS #######################\n",
    "######## please edit the values of this block only ########\n",
    "###########################################################\n",
    "\n",
    "# define hillshade file\n",
    "HS_FILE = './test_data/DEM/TDX_Merapi_WGS84_HS.tif'\n",
    "\n",
    "# define lon and lat files\n",
    "LON_FILE = './test_data/CSK_dsc/geo/20200910.lon'\n",
    "LAT_FILE = './test_data/CSK_dsc/geo/20200910.lat'\n",
    "\n",
    "# define parameter text file\n",
    "PARAM_FILE = './test_data/CSK_dsc/params.txt'\n",
    "\n",
    "# define map region of interest\n",
    "lon_lims = [110.425, 110.45]\n",
    "lat_lims = [-7.555, -7.535]\n",
    "\n",
    "# define colour range {min max} (min = -max)\n",
    "vmax = 3 # range of colourscale in meters\n",
    "\n",
    "# define file names for data, lon and lat\n",
    "DIRECTORY_PATH = \"./test_data/CSK_dsc/OFFS/\"\n",
    "# define path to ccp and ccs files\n",
    "DIRECTORY_PATH_CCS = \"./test_data/CSK_dsc/CCS/\"\n",
    "\n",
    "# Set the regular expression pattern to match the file names\n",
    "PATTERN = r\"^c[0-9]+_c[0-9]+_disp_[0-9]+_[0-9]+\\.txt$\"\n",
    "# Set the regular expression pattern to match the ccs file names\n",
    "PATTERN_CCS = r\"^c[0-9]+_c[0-9]+_ccs_[0-9]+_[0-9]+$\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['c20200927_c20201113_disp_42_20.txt', 'c20200927_c20201113_disp_74_36.txt', 'c20200927_c20201113_disp_108_52.txt', 'c20200927_c20201113_disp_140_68.txt', 'c20200927_c20201113_disp_174_84.txt', 'c20200927_c20201113_disp_206_100.txt', 'c20200927_c20201113_disp_240_116.txt', 'c20200927_c20201113_disp_272_132.txt', 'c20200927_c20201113_disp_306_148.txt', 'c20200927_c20201113_disp_340_164.txt', 'c20200927_c20201113_disp_372_180.txt']\n",
      "['c20200927_c20201113_ccs_42_20', 'c20200927_c20201113_ccs_74_36', 'c20200927_c20201113_ccs_108_52', 'c20200927_c20201113_ccs_140_68', 'c20200927_c20201113_ccs_174_84', 'c20200927_c20201113_ccs_206_100', 'c20200927_c20201113_ccs_240_116', 'c20200927_c20201113_ccs_272_132', 'c20200927_c20201113_ccs_306_148', 'c20200927_c20201113_ccs_340_164', 'c20200927_c20201113_ccs_372_180']\n"
     ]
    }
   ],
   "source": [
    "# open hillshade file and re-order offset and CCS files\n",
    "\n",
    "# open hill shade file with rasterio\n",
    "DEM_HS = rio.open(HS_FILE)\n",
    "SHADING = DEM_HS.read(1,masked=True) # rasterio bands are indexed from 1\n",
    "\n",
    "# extract DEM extent\n",
    "DEM_EXTENT=[DEM_HS.bounds.left,DEM_HS.bounds.right,DEM_HS.bounds.bottom,DEM_HS.bounds.top]\n",
    "\n",
    "# reorder file using Post_processing.reorder_files\n",
    "matching_files = sm.Post_processing.reorder_files(DIRECTORY_PATH,PATTERN,0)\n",
    "matching_files_ccs = sm.Post_processing.reorder_files(DIRECTORY_PATH_CCS,PATTERN_CCS,0)\n",
    "\n",
    "# test if file ordering has worked\n",
    "print(matching_files)\n",
    "print(matching_files_ccs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read parameters from text file\n",
    "config = configparser.ConfigParser()\n",
    "config.read(PARAM_FILE)\n",
    "WIDTH = int(config.get('params', 'width'))\n",
    "LINES = int(config.get('params', 'lines'))\n",
    "WIDTH_CCS = int(config.get('params', 'width_ccs'))\n",
    "LINES_CCS = int(config.get('params', 'lines_ccs'))\n",
    "R_START = int(config.get('params', 'r_start'))\n",
    "A_START = int(config.get('params', 'a_start'))\n",
    "R_STEP = int(config.get('params', 'r_step'))\n",
    "A_STEP = int(config.get('params', 'a_step'))\n",
    "HEADING = float(config.get('params', 'heading'))\n",
    "MEAN_INC = float(config.get('params', 'mean_inc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from files into classes\n",
    "\n",
    "datastack = sm.Post_processing.MultiKernel(DIRECTORY_PATH,\n",
    "                                           matching_files,\n",
    "                                           DIRECTORY_PATH_CCS,\n",
    "                                           matching_files_ccs,\n",
    "                                           LAT_FILE,\n",
    "                                           LON_FILE,\n",
    "                                           HEADING,\n",
    "                                           MEAN_INC,\n",
    "                                           LINES_CCS,\n",
    "                                           WIDTH_CCS)\n",
    "datastack.get_params_from_file_name()\n",
    "datastack.get_latlon_from_file(WIDTH)\n",
    "datastack.add_lat_lon_to_data(R_START,A_START)\n",
    "datastack.crop_stack_ccs(R_STEP,A_STEP)\n",
    "stacked_data = datastack.assign_data_to_stack(R_STEP,A_STEP)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x1200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# test some plotting functions\n",
    "# next to do 8\n",
    "test_obj = stacked_data[4]\n",
    "sm.plot.plot_hist(test_obj,'Mag_vec', 1000,[],1, [0,10])\n",
    "R_off_compare = getattr(test_obj,'R_off')\n",
    "A_off_compare = getattr(test_obj,'A_off')\n",
    "lon_off_compare = getattr(test_obj,'Lon_off')\n",
    "lat_off_compare = getattr(test_obj,'Lat_off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# # Assuming your 3D array is named 'data_array' with shape (3, M, N)\n",
    "# # Sheet 0: Data, Sheet 1: X coordinates, Sheet 2: Y coordinates\n",
    "# data = data_array[0]\n",
    "# x_coords = data_array[1]\n",
    "# y_coords = data_array[2]\n",
    "\n",
    "# window_size = 5\n",
    "\n",
    "# # Calculate standard deviation using sliding window after removing outliers, removing the plane\n",
    "# std_result = sliding_window_std(data, x_coords, y_coords, window_size)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0. nan  2.  3.]\n",
      " [ 4. nan  6.  7.]\n",
      " [ 8.  9. nan 11.]\n",
      " [nan 13. 14. 15.]]\n",
      "[[[[ 0. nan]\n",
      "   [ 4. nan]]\n",
      "\n",
      "  [[nan  2.]\n",
      "   [nan  6.]]\n",
      "\n",
      "  [[ 2.  3.]\n",
      "   [ 6.  7.]]]\n",
      "\n",
      "\n",
      " [[[ 4. nan]\n",
      "   [ 8.  9.]]\n",
      "\n",
      "  [[nan  6.]\n",
      "   [ 9. nan]]\n",
      "\n",
      "  [[ 6.  7.]\n",
      "   [nan 11.]]]\n",
      "\n",
      "\n",
      " [[[ 8.  9.]\n",
      "   [nan 13.]]\n",
      "\n",
      "  [[ 9. nan]\n",
      "   [13. 14.]]\n",
      "\n",
      "  [[nan 11.]\n",
      "   [14. 15.]]]]\n",
      "(3, 3, 2, 2)\n",
      "[[ 0. nan  4. nan]\n",
      " [nan  2. nan  6.]\n",
      " [ 2.  3.  6.  7.]\n",
      " [ 4. nan  8.  9.]\n",
      " [nan  6.  9. nan]\n",
      " [ 6.  7. nan 11.]\n",
      " [ 8.  9. nan 13.]\n",
      " [ 9. nan 13. 14.]\n",
      " [nan 11. 14. 15.]]\n",
      "(9, 4)\n",
      "[2.         2.         2.06155281 2.1602469  1.5        2.1602469\n",
      " 2.1602469  2.1602469  1.69967317]\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# test reshape\n",
    "data_test = np.reshape(np.array([float(i) for i in range(16)]),(4,4))\n",
    "data_test[0,1] = np.nan\n",
    "data_test[1,1] = np.nan\n",
    "data_test[2,2] = np.nan\n",
    "data_test[3,0] = np.nan\n",
    "print(data_test)\n",
    "window_size = 2\n",
    "window_shape = (window_size, window_size)\n",
    "windows = np.lib.stride_tricks.sliding_window_view(data_test, window_shape)\n",
    "print(windows)\n",
    "print(np.shape(windows))\n",
    "d_shape = np.shape(windows)\n",
    "reshaped_windows = windows.reshape(d_shape[0]*d_shape[1],d_shape[2]*d_shape[3])\n",
    "# reshaped_windows = reshaped_windows.reshape(d_shape[0]*d_shape[1],d_shape[2]*d_shape[3])\n",
    "\n",
    "print(reshaped_windows)\n",
    "print(np.shape(reshaped_windows))\n",
    "\n",
    "std_test = np.nanstd(reshaped_windows,axis=1)\n",
    "print(std_test)\n",
    "# data_r = data.reshape((4,3,2,2))\n",
    "# print(data_r)\n",
    "# print(data_r.reshape((12,4)))\n",
    "plt.close('all')\n",
    "\n",
    "print(np.nanstd([1.2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removing outliers\n",
      "removing outliers\n",
      "removing outliers\n",
      "removing outliers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/envs/PhD/lib/python3.8/site-packages/numpy/lib/nanfunctions.py:1583: RuntimeWarning: All-NaN slice encountered\n",
      "  result = np.apply_along_axis(_nanquantile_1d, axis, a, q,\n",
      "/Applications/anaconda3/envs/PhD/lib/python3.8/site-packages/numpy/lib/nanfunctions.py:1583: RuntimeWarning: All-NaN slice encountered\n",
      "  result = np.apply_along_axis(_nanquantile_1d, axis, a, q,\n",
      "/Applications/anaconda3/envs/PhD/lib/python3.8/site-packages/numpy/lib/nanfunctions.py:1583: RuntimeWarning: All-NaN slice encountered\n",
      "  result = np.apply_along_axis(_nanquantile_1d, axis, a, q,\n",
      "/Applications/anaconda3/envs/PhD/lib/python3.8/site-packages/numpy/lib/nanfunctions.py:1583: RuntimeWarning: All-NaN slice encountered\n",
      "  result = np.apply_along_axis(_nanquantile_1d, axis, a, q,\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import lstsq\n",
    "import multiprocessing\n",
    "\n",
    "from sliding_window_std_functions import sliding_window_std, remove_outliers, remove_plane\n",
    "### Start of functions\n",
    "\n",
    "### End of functions\n",
    "\n",
    "    # test std function \n",
    "std_r_list = []\n",
    "std_a_list = []\n",
    "deplane = True\n",
    "data_to_process_r = []\n",
    "data_to_process_a = []\n",
    "for obj in datastack.Stack:\n",
    "    # get data\n",
    "    offs_R = obj.R_off\n",
    "    offs_A = obj.A_off\n",
    "    offs_lon = getattr(obj, 'Lon_off')\n",
    "    offs_lat = getattr(obj, 'Lat_off')\n",
    "\n",
    "    data_to_process_r.append((offs_R,offs_lon,offs_lat,5,deplane))\n",
    "    data_to_process_a.append((offs_A,offs_lon,offs_lat,5,deplane))\n",
    "# i = 0\n",
    "# for data in data_to_process_r:\n",
    "#     print(i)\n",
    "#     std_r = sliding_window_std(data)\n",
    "#     std_r_list.append(std_r)\n",
    "#     i +=1\n",
    "\n",
    "with multiprocessing.Pool(processes=4) as pool_r:\n",
    "    results_r = pool_r.map(sliding_window_std, data_to_process_r)\n",
    "\n",
    "with multiprocessing.Pool(processes=4) as pool_a:\n",
    "    results_a = pool_a.map(sliding_window_std, data_to_process_a)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for obj in datastack.Stack:\n",
    "#     # get data\n",
    "#     offs_R = obj.R_off\n",
    "#     offs_A = obj.A_off\n",
    "#     offs_lon = getattr(obj, 'Lon_off')\n",
    "#     offs_lat = getattr(obj, 'Lat_off')\n",
    "\n",
    "#     print('starting r')\n",
    "#     std_r = sliding_window_std(offs_R, offs_lon, offs_lat,5,deplane)\n",
    "#     print('starting a')\n",
    "#     std_a = sliding_window_std(offs_A, offs_lon, offs_lat,5,deplane)\n",
    "#     print('done')\n",
    "\n",
    "#     std_a[std_a<0] = -1\n",
    "#     std_r[std_r<0] = -1\n",
    "#     # fig, ax = plt.subplots(1,2,figsize=(10,10))\n",
    "#     # std_plot_r= ax[0].imshow(std_r,vmax=np.nanmax(std_r),vmin=0)\n",
    "#     # std_plot_a= ax[1].imshow(std_a,vmax=np.nanmax(std_a),vmin=0)\n",
    "#     # plt.colorbar(std_plot_r,ax=ax[0])\n",
    "#     # plt.colorbar(std_plot_a,ax=ax[1])\n",
    "#     # ax[0].set_title(f'range offset std ({obj.R_win},{obj.A_win})')\n",
    "#     # ax[1].set_title(f'azimuth offset std ({obj.R_win},{obj.A_win})')\n",
    "#     # print(np.nanmin(std_r),np.nanmax(std_r))\n",
    "#     # print(np.nanmin(std_a),np.nanmax(std_a))\n",
    "#     std_a_list.append(std_a)\n",
    "#     std_r_list.append(std_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "%matplotlib osx\n",
    "R_offs = [getattr(obj,'R_off') for obj in datastack.Stack]\n",
    "A_offs = [getattr(obj,'A_off') for obj in datastack.Stack]\n",
    "\n",
    "# results_r = std_r_list\n",
    "# results_a = std_r_list\n",
    "\n",
    "\n",
    "for idx, (std_r_i, std_a_i,R_off,A_off) in enumerate(zip(results_r,results_a,R_offs,A_offs)):\n",
    "    print(idx)\n",
    "    fig, ax = plt.subplots(2,2,figsize=(10,10))\n",
    "    plot_r = ax[0,0].imshow(R_off,vmax=3,vmin=-3,interpolation='nearest',cmap=cm.vik)\n",
    "    plot_a = ax[0,1].imshow(A_off,vmax=3,vmin=-3,interpolation='nearest',cmap=cm.vik)\n",
    "    std_plot_r= ax[1,0].imshow(std_r_i,vmax=1,vmin=0,interpolation='nearest')\n",
    "    std_plot_a= ax[1,1].imshow(std_a_i,vmax=1,vmin=0,interpolation='nearest')\n",
    "    plt.colorbar(plot_r,ax=ax[0,0])\n",
    "    plt.colorbar(plot_a,ax=ax[0,1])\n",
    "    plt.colorbar(std_plot_r,ax=ax[1,0])\n",
    "    plt.colorbar(std_plot_a,ax=ax[1,1])\n",
    "    ax[0,0].set_title(f'range offset: {datastack.Stack[idx].R_win},{datastack.Stack[idx].A_win}')\n",
    "    ax[1,0].set_title(f'range offset std: {datastack.Stack[idx].R_win},{datastack.Stack[idx].A_win}')\n",
    "    ax[0,1].set_title(f'azimuth offset: {datastack.Stack[idx].R_win},{datastack.Stack[idx].A_win}')\n",
    "    ax[1,1].set_title(f'azimuth offset std: {datastack.Stack[idx].R_win},{datastack.Stack[idx].A_win}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(np.sum(np.isnan(std_r_list[0])))\n",
    "# print(np.sum(np.isnan(R_offs[0])))\n",
    "# print(np.size(std_r_list[0]))\n",
    "# print(np.size(R_offs[0]))\n",
    "\n",
    "import os\n",
    "\n",
    "os.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.24627206889277833, 0.15549784225129554, 0.11092934351419283, 0.08335439219646766, 0.0642002138658901, 0.0530811423163696, 0.04318671612325679, 0.03534013245803418, 0.02938738616356713, 0.025480638631335505, 0.022170723249342012]\n",
      "[0.3308372455881766, 0.24750508656157197, 0.19040948641565136, 0.1516468252720329, 0.12101674481514363, 0.10015444777186157, 0.08460134545463349, 0.07192659086669079, 0.059425197206630455, 0.050917319673938755, 0.044816070767385925]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fdbc0664a00>]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1   HIToolbox                           0x00007ff81e4180c2 _ZN15MenuBarInstance22RemoveAutoShowObserverEv + 30\n",
      "2   HIToolbox                           0x00007ff81e3face3 _ZN15MenuBarInstance21UpdateAggregateUIModeE21MenuBarAnimationStylehhh + 1125\n",
      "3   HIToolbox                           0x00007ff81e3fa7a4 _ZN15MenuBarInstance16ForEachMenuBarDoEU13block_pointerFvPS_E + 46\n",
      "4   HIToolbox                           0x00007ff81e3fa762 SetSystemUIMode + 209\n",
      "5   AppKit                              0x00007ff817f58293 -[NSApplication _setPresentationOptions:instance:flags:] + 1157\n",
      "6   AppKit                              0x00007ff817dad075 -[NSApplication _updateFullScreenPresentationOptionsForInstance:] + 614\n",
      "7   CoreFoundation                      0x00007ff814ac23d4 __CFNOTIFICATIONCENTER_IS_CALLING_OUT_TO_AN_OBSERVER__ + 137\n",
      "8   CoreFoundation                      0x00007ff814b5c41a ___CFXRegistrationPost_block_invoke + 88\n",
      "9   CoreFoundation                      0x00007ff814b5c369 _CFXRegistrationPost + 536\n",
      "10  CoreFoundation                      0x00007ff814a958f9 _CFXNotificationPost + 735\n",
      "11  Foundation                          0x00007ff8158d1abc -[NSNotificationCenter postNotificationName:object:userInfo:] + 82\n",
      "12  AppKit                              0x00007ff817f588f8 spacesNotificationHandler + 119\n",
      "13  SkyLight                            0x00007ff8196f923d _ZN12_GLOBAL__N_123notify_datagram_handlerEj15CGSDatagramTypePvmS1_ + 1030\n",
      "14  SkyLight                            0x00007ff819a0c05a _ZN21CGSDatagramReadStream26dispatchMainQueueDatagramsEv + 202\n",
      "15  SkyLight                            0x00007ff819a0bf81 ___ZN21CGSDatagramReadStream15mainQueueWakeupEv_block_invoke + 18\n",
      "16  libdispatch.dylib                   0x00007ff8148707fb _dispatch_call_block_and_release + 12\n",
      "17  libdispatch.dylib                   0x00007ff814871a44 _dispatch_client_callout + 8\n",
      "18  libdispatch.dylib                   0x00007ff81487e7b9 _dispatch_main_queue_drain + 952\n",
      "19  libdispatch.dylib                   0x00007ff81487e3f3 _dispatch_main_queue_callback_4CF + 31\n",
      "20  CoreFoundation                      0x00007ff814b0b5f0 __CFRUNLOOP_IS_SERVICING_THE_MAIN_DISPATCH_QUEUE__ + 9\n",
      "21  CoreFoundation                      0x00007ff814acbb70 __CFRunLoopRun + 2454\n",
      "22  CoreFoundation                      0x00007ff814acab60 CFRunLoopRunSpecific + 560\n",
      "23  HIToolbox                           0x00007ff81e418766 RunCurrentEventLoopInMode + 292\n",
      "24  HIToolbox                           0x00007ff81e418576 ReceiveNextEventCommon + 679\n",
      "25  HIToolbox                           0x00007ff81e4182b3 _BlockUntilNextEventMatchingListInModeWithFilter + 70\n",
      "26  AppKit                              0x00007ff817c1b2f3 _DPSNextEvent + 909\n",
      "27  AppKit                              0x00007ff817c1a174 -[NSApplication(NSEvent) _nextEventMatchingEventMask:untilDate:inMode:dequeue:] + 1219\n",
      "28  AppKit                              0x00007ff817c0c7b7 -[NSApplication run] + 586\n",
      "29  libffi.8.dylib                      0x000000010961ba22 ffi_call_unix64 + 82\n",
      "30  ???                                 0x00007ff7b6dabcc0 0x0 + 140701901438144\n"
     ]
    }
   ],
   "source": [
    "mask = ~np.isnan(results_r[10])\n",
    "r_std_list = [np.nansum(map_r[mask])/np.sum(~np.isnan(map_r[mask])) for map_r in results_r]\n",
    "a_std_list = [np.nansum(map_a[mask])/np.sum(~np.isnan(map_a[mask])) for map_a in results_a]\n",
    "n_data = [np.sum(~np.isnan(map_r[mask])) for map_r in results_r]\n",
    "n_data = n_data/np.max(n_data)\n",
    "\n",
    "print(r_std_list)\n",
    "print(a_std_list)\n",
    "\n",
    "fig, ax = plt.subplots(1,1,figsize = (10,10))\n",
    "ax.plot(r_std_list)\n",
    "ax.plot(a_std_list)\n",
    "ax.plot(np.array(r_std_list)+np.array(a_std_list))\n",
    "ax.plot(n_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib osx\n",
    "fig, ax = plt.subplots(1,1,figsize=(10,10))\n",
    "for obj in stacked_data[::-2]:\n",
    "    sm.plot.plot_hist(obj,'Mag_vec', 1000,(fig,ax), 0.5, [0,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import csv\n",
    "from IPython.display import clear_output\n",
    "N_test = 200\n",
    "# get set of random integers for dataset testing:\n",
    "idx_rand = [random.randint(0,np.size(test_obj.R_off_vec)) for i in range(N_test)]\n",
    "print(test_obj.R_win, test_obj.A_win)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# manually check many different vectors to classify as outlier, inlier and confidence on deformation\n",
    "\n",
    "## make testing data\n",
    "# store R_idx, A_idx, in/out flag, def flag\n",
    "# in/out flag:\n",
    "#   0 : outlier high-confidence0\n",
    "#   1 : outlier low-confidence\n",
    "#   2 : inlier low-confidence\n",
    "#   3 : inlier high confidence \n",
    "\n",
    "# def flag:0\n",
    "\n",
    "#   0 : no def high-confidence\n",
    "#   1 : no def low-confidence\n",
    "#   2 : def low-confidence\n",
    "#   3 : def high confidence 00\n",
    "0\n",
    "\n",
    "\n",
    "\n",
    "test_file = f'./test_data/CSK_dsc/{test_obj.R_win}_{test_obj.A_win}_test_set.csv'\n",
    "\n",
    "init_csv = int(input('initialize csv file?'))\n",
    "\n",
    "# writing to csv file \n",
    "if init_csv == 1:\n",
    "    with open(test_file, 'w') as csvfile: \n",
    "        # creating a csv writer object \n",
    "        csvwriter = csv.writer(csvfile) \n",
    "            \n",
    "        # writing the fields \n",
    "        csvwriter.writerow(['R idx', 'A idx', 'in/out flag', 'def flag']) \n",
    "\n",
    "test_data = []\n",
    "N_test = 1000\n",
    "# plt.ion()\n",
    "counter = 1\n",
    "for idx in idx_rand:\n",
    "    if np.mod(counter,10)==0:\n",
    "        test_data_df = pd.DataFrame(test_data)\n",
    "        test_data_df.to_csv(test_file, mode='a', index=False, header=False)\n",
    "        test_data = []\n",
    "    sm.plot.plot_rand_vec(test_obj,idx,5,0.002,0.3,2)\n",
    "    plt.show(block=False)\n",
    "    in_out_flag = int(input('what is the in/out flag? 0:outlier high conf, 1:outlier low conf,  2: inlier low conf, 3: inlier high conf'))\n",
    "    if in_out_flag not in [0,1,2,3]:\n",
    "        print('ERROR: flag needs to be 0, 1, 2, or 3')\n",
    "        break\n",
    "    def_flag = int(input('what is the def flag? 0: no def high conf, 1: no def low conf., 2: def low conf, 3: def high conf'))\n",
    "    if in_out_flag not in [0,1,2,3]:\n",
    "        print('ERROR: flag needs to be 0, 1, 2, or 3')\n",
    "        break\n",
    "    test_data.append([test_obj.R_idx_vec[idx], test_obj.A_idx_vec[idx], in_out_flag, def_flag])\n",
    "    plt.clf()\n",
    "    clear_output(wait=True)\n",
    "    counter += 1\n",
    "\n",
    "test_data = pd.DataFrame(test_data)\n",
    "test_data.to_csv(test_file, mode='a', index=False, header=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.append([test_obj.R_idx_vec[idx], test_obj.A_idx_vec[idx], in_out_flag, def_flag])\n",
    "test_data = pd.DataFrame(test_data)\n",
    "test_data.to_csv(test_file, mode='a', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print vector field\n",
    "%matplotlib osx\n",
    "# sm.plot.plot_vec_attr(test_obj,'Phase',10,50,[0,360],1,shading,DEM_extent)\n",
    "sm.plot.plot_vec_attr(test_obj,'Phase',5,75,0.005,[0,360],5,SHADING,DEM_EXTENT,[-7.55, -7.53],[110.43,110.46])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # test long calculation of local weighted L2\n",
    "# test_obj.calc_local_L2()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot local dissimilarity vector\n",
    "# sm.plot.plot_vec_attr(test_obj,'wL2',5 ,50,0.01,[0,5]  ,1,SHADING,DEM_EXTENT,[-7.546, -7.533],[110.435,110.450])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test HDBSCAN\n",
    "min_cluster_size = 16 # smallest minimum cluster size\n",
    "# compute max overlap\n",
    "overlap = 4*np.ceil((test_obj.R_win/R_STEP) * (test_obj.A_win/A_STEP))\n",
    "print(overlap)\n",
    "min_cluster_size = np.max([int(overlap),min_cluster_size])\n",
    "min_samples = 1\n",
    "\n",
    "single_cluster = False # setting to true doesn't break code but makes it run way slower\n",
    "cluster_selection_epsilon = 0.3 # doesnt do much"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run HDBSCAN\n",
    "test_obj.prep_DBSCAN(1,1,100)\n",
    "test_obj.run_PCA(4)\n",
    "test_obj.run_HDBSCAN(min_cluster_size,min_samples,single_cluster,cluster_selection_epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot results from HDBSCAN labels and outlier factor\n",
    "sm.plot.plot_vec_attr(test_obj,'HDBSCAN_labels',3,50,0.01,[-1,0],5,SHADING,DEM_EXTENT,[-7.546, -7.533],[110.435,110.450])\n",
    "sm.plot.plot_vec_attr(test_obj,'HDBSCAN_labels',10,50,0.01,[-1,0],5,SHADING,DEM_EXTENT,[-7.546, -7.533],[110.435,110.450])\n",
    "sm.plot.plot_vec_attr(test_obj,'HDBSCAN_outlier_scores',3,50,0.01,[-1,5],5,SHADING,DEM_EXTENT,[-7.546, -7.533],[110.435,110.450])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove HDBSCAN outliers\n",
    "# before\n",
    "sm.plot.plot_vec_attr(test_obj,'Phase',3,50,0.01,[0,360],1,SHADING,DEM_EXTENT,[-7.546, -7.533],[110.435,110.450])\n",
    "sm.plot.plot_vec_attr(test_obj,'HDBSCAN_outlier_scores',3,50,0.01,[-1,5],1,SHADING,DEM_EXTENT,[-7.546, -7.533],[110.435,110.450])\n",
    "\n",
    "# remove outliers\n",
    "test_obj.rem_outliers_HDBSCAN()\n",
    "\n",
    "# after\n",
    "sm.plot.plot_vec_attr(test_obj,'Phase',3,50,0.01,[0,360],1,SHADING,DEM_EXTENT,[-7.546, -7.533],[110.435,110.450])\n",
    "sm.plot.plot_vec_attr(test_obj,'HDBSCAN_outlier_scores',3,50,0.01,[-1,5],1,SHADING,DEM_EXTENT,[-7.546, -7.533],[110.435,110.450])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query points\n",
    "q1 = [110.446216,-7.536389] # stable no veg north\n",
    "q2 = [110.42647,-7.53297] # stable veg north west\n",
    "q3 = [110.4421429,-7.5377992] # L1888\n",
    "q4 = [110.44214,-7.54237] # L1998 large disp\n",
    "q5 = [110.44013,-7.54678] # stable no veg south\n",
    "q6 = [110.44200,-7.53604] # L1956 offset gradient\n",
    "query_points = np.stack((q1,q2,q3,q4,q5,q6))\n",
    "r = 50\n",
    "\n",
    "indeces = [0,2,4,6]\n",
    "stats_list, coordinate_circles = datastack.query_point_stack('R_off_vec',\n",
    "                                                             query_points[:,1],\n",
    "                                                             query_points[:,0],\n",
    "                                                             r,\n",
    "                                                             indeces)\n",
    "\n",
    "print(stats_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "\n",
    "# cross_plot(test_obj,'HDBSCAN_outlier_scores','wL2',0,300)\n",
    "# sm.plot.cross_plot(test_obj,'HDBSCAN_outlier_scores','wL2',1,300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot range offset for different window sizes to see nan mask\n",
    "indeces = [0,2,4,6]\n",
    "r_offset = np.stack([obj.R_off for obj in datastack.Stack])\n",
    "plot_data = [r_offset[idx] for idx in indeces]\n",
    "plot_data = plot_data + [np.isnan(r_offset[idx]) for idx in range(4)]\n",
    "\n",
    "cmaps = [cm.vik,cm.vik,cm.vik,cm.vik,\n",
    "         'Greys','Greys','Greys','Greys']\n",
    "min_clim = [-vmax,-vmax,-vmax,-vmax,\n",
    "            0,0,0,0]\n",
    "\n",
    "max_clim = [vmax,vmax,vmax,vmax,\n",
    "            1,1,1,1]\n",
    "\n",
    "\n",
    "# initiate figure\n",
    "textsize = 15\n",
    "plt.rc('font', size=textsize) \n",
    "fig=plt.figure(figsize=(20,12))\n",
    "gs=GridSpec(2,4) # 3 rows, 5 columns\n",
    "axes = [fig.add_subplot(gs[i,j]) for i in range(2) for j in range(4)]\n",
    "\n",
    "for ax,p_data,cmap,clim_min,clim_max in zip(axes,plot_data,cmaps,min_clim,max_clim):\n",
    "    ax.imshow(p_data,cmap=cmap,vmin=clim_min,vmax=clim_max, interpolation='Nearest')\n",
    "    ax.set_axis_off()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perfrom outlier detection and removal for all windows\n",
    "import time\n",
    "start = time.time()\n",
    "for obj in stacked_data:\n",
    "    min_cluster_size = 16 # smallest minimum cluster size\n",
    "    print(f'current window size: {obj.R_win}, {obj.A_win}')\n",
    "    overlap = 4*np.ceil((obj.R_win/R_STEP) * (obj.A_win/A_STEP))\n",
    "    min_cluster_size = np.max([int(overlap),min_cluster_size])\n",
    "    min_samples = 1\n",
    "    # run HDBSCAN\n",
    "    obj.prep_DBSCAN(1,1,100)\n",
    "    obj.run_PCA(4)\n",
    "    obj.run_HDBSCAN(min_cluster_size,min_samples,single_cluster,cluster_selection_epsilon)\n",
    "    obj.rem_outliers_HDBSCAN()\n",
    "    print(f'time: {time.time()-start}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot range offset for different window sizes to see nan mask\n",
    "indeces = [0,2,4,6]\n",
    "r_offset = np.stack([obj.R_off for obj in datastack.Stack])\n",
    "plot_data = [r_offset[idx] for idx in indeces]\n",
    "plot_data = plot_data + [np.isnan(r_offset[idx]) for idx in range(4)]\n",
    "nan_masks = np.stack([np.isnan(r_offset[idx]) for idx in range(4)])\n",
    "nan_frac = np.sum(nan_masks, axis=0) / 4\n",
    "\n",
    "fig=plt.figure(figsize=(7,7))\n",
    "plt.imshow(nan_frac)\n",
    "nan_frac2 = copy.deepcopy(nan_frac)\n",
    "nan_frac2[nan_frac > 0.5] = np.nan\n",
    "nan_frac2[nan_frac <= 0.5] = 1\n",
    "fig=plt.figure(figsize=(7,7))\n",
    "plt.imshow(nan_frac2)\n",
    "\n",
    "cmaps = [cm.vik,cm.vik,cm.vik,cm.vik,\n",
    "         'Greys','Greys','Greys','Greys']\n",
    "min_clim = [-vmax,-vmax,-vmax,-vmax,\n",
    "            0,0,0,0]\n",
    "\n",
    "max_clim = [vmax,vmax,vmax,vmax,\n",
    "            1,1,1,1]\n",
    "\n",
    "\n",
    "# initiate figure\n",
    "textsize = 15\n",
    "plt.rc('font', size=textsize) \n",
    "fig=plt.figure(figsize=(20,12))\n",
    "gs=GridSpec(2,4) # 3 rows, 5 columns\n",
    "axes = [fig.add_subplot(gs[i,j]) for i in range(2) for j in range(4)]\n",
    "\n",
    "for ax,p_data,cmap,clim_min,clim_max in zip(axes,plot_data,cmaps,min_clim,max_clim):\n",
    "    ax.imshow(p_data,cmap=cmap,vmin=clim_min,vmax=clim_max, interpolation='Nearest')\n",
    "    ax.set_axis_off()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMKA_R_off, MKA_A_off = datastack.Run_MKA([0,2,4,6],comp_lim=0.50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "def Run_RSS(stack_obj,indeces=[],window_size=5,deramp=True):\n",
    "        # \"\"\"\n",
    "        # Calculate residual sum of squares. user can specify window size and can turn off deramping if desired\n",
    "\n",
    "        # Args:\n",
    "        #     indices (list, optional): indices of slices from datastack used for MKA. Defaults to [], use all data.\n",
    "        #     window_size (int, optional): window dimension for MKA, odd numbers \n",
    "        #                                  prefered because of pixel centering. \n",
    "        #                                  Defaults to 5.\n",
    "        #     deramp (bool, optional): flag for deramping data in map coordinates \n",
    "        #                              to allow for better estimates in gradual displacement \n",
    "        #                              fields. deramping in map coordinates does not do local \n",
    "        #                              transformation to ortholinear projection so there may \n",
    "        #                              be inaccuracies. \n",
    "        # Returns:\n",
    "        #     RSS_list: list of resisual sum of squares\n",
    "        # \"\"\"\n",
    "        # get stack data\n",
    "        if indeces==[]:\n",
    "            stack_R = [obj.R_off for obj in stack_obj.Stack]\n",
    "            stack_A = [obj.A_off for obj in stack_obj.Stack]\n",
    "            stack_lons = [getattr(obj,'Lon_off') for obj in stack_obj.Stack]\n",
    "            stack_lats = [getattr(obj,'Lat_off') for obj in stack_obj.Stack]\n",
    "\n",
    "        else:\n",
    "            substack = [stack_obj.Stack[i] for i in indeces]\n",
    "            stack_R = np.stack([obj.R_off for obj in substack],axis=0)\n",
    "            stack_A = np.stack([obj.A_off for obj in substack],axis=0)\n",
    "            stack_lons = np.stack([getattr(obj,'Lon_off') for obj in substack])\n",
    "            stack_lats = np.stack([getattr(obj,'Lat_off') for obj in substack])\n",
    "\n",
    "        # create list of rss values\n",
    "        rss_list = []\n",
    "\n",
    "        for stack_r,stack_a,stack_lon,stack_lat in zip(stack_R,stack_A,stack_lons,stack_lats):\n",
    "            # set window size according to stack dimensions\n",
    "            window_shape = (window_size, window_size)\n",
    "            print(np.shape(window_shape))\n",
    "            # use np.lib.stride_tricks.sliding_window_view to devided data into windows\n",
    "            # 1.2xfaster than sklearn view_as_windows\n",
    "            win_data_r = np.lib.stride_tricks.sliding_window_view(stack_r, window_shape)\n",
    "            win_data_a = np.lib.stride_tricks.sliding_window_view(stack_a, window_shape)\n",
    "\n",
    "            win_data_lon = np.lib.stride_tricks.sliding_window_view(stack_lon, window_shape)\n",
    "            win_data_lat = np.lib.stride_tricks.sliding_window_view(stack_lat, window_shape)\n",
    "            \n",
    "            # define shape of multi-kernel averaged map (same as input data), filled with nan\n",
    "            Avg_map_r = []\n",
    "            Avg_map_a = []\n",
    "\n",
    "\n",
    "\n",
    "            # per window, go take 95% confidence interval data and take average (mean)\n",
    "            for win_i in range(win_data_r.shape[0]):\n",
    "                if win_i % 5 == 0:\n",
    "                    print('win_i', win_i)\n",
    "                for win_j in range(win_data_r.shape[1]):\n",
    "                    # extract relevant window\n",
    "                    win_rng = np.array(win_data_r[win_i, win_j])\n",
    "                    win_azi = np.array(win_data_a[win_i, win_j])\n",
    "                    \n",
    "                    lon_win = np.array(win_data_lon[win_i,win_j])\n",
    "                    lat_win = np.array(win_data_lat[win_i,win_j])\n",
    "                    # print(win_rng,win_azi,lon_win,lat_win)\n",
    "                    # calculate 95 % confidence interval\n",
    "                    percentiles_r = np.nanpercentile(win_rng, [2.5, 97.5])\n",
    "                    percentiles_a = np.nanpercentile(win_azi, [2.5, 97.5])\n",
    "                    # mask data outside 95% confidence interval with nan\n",
    "                    mask_r = (win_rng < percentiles_r[0]) | (win_rng > percentiles_r[1])\n",
    "                    mask_a = (win_azi < percentiles_a[0]) | (win_azi > percentiles_a[1])\n",
    "                    mask = (mask_r) | (mask_a)\n",
    "                    # print(mask)\n",
    "                    win_rng[mask] = np.nan\n",
    "                    win_azi[mask] = np.nan\n",
    "                    lon_win[mask] = np.nan\n",
    "                    lat_win[mask] = np.nan\n",
    "                    \n",
    "                    #deramp\n",
    "                    if np.all(np.isnan(win_rng)):\n",
    "                        deramped_r = np.nan\n",
    "                        deramped_a = np.nan\n",
    "                    else:\n",
    "                        if deramp:\n",
    "                            X_data = np.transpose(np.stack((lon_win.flatten(),lat_win.flatten())))\n",
    "                            Y_data_r = win_rng.flatten()\n",
    "                            X_data = X_data[np.where(~np.isnan(Y_data_r))]\n",
    "                            Y_data_r = Y_data_r[np.where(~np.isnan(Y_data_r))]\n",
    "                            reg = linear_model.LinearRegression().fit(X_data, Y_data_r)\n",
    "                            deramped_r =win_rng.flatten() - lon_win.flatten() * reg.coef_[0] - lat_win.flatten() * reg.coef_[1]\n",
    "\n",
    "                            Y_data_a = win_azi.flatten()\n",
    "                            Y_data_a = Y_data_a[np.where(~np.isnan(Y_data_a))]\n",
    "                            reg = linear_model.LinearRegression().fit(X_data, Y_data_a)\n",
    "                            deramped_a =win_azi.flatten() - lon_win.flatten() * reg.coef_[0] - lat_win.flatten() * reg.coef_[1]\n",
    "                        else:\n",
    "                            deramped_r = win_rng.flatten()\n",
    "                            deramped_a = win_azi.flatten()\n",
    "                    # remove -1 entries (all nans)\n",
    "                    # deramped_a[deramped_a==-1] = np.nan\n",
    "                    # deramped_r[deramped_r==-1] = np.nan\n",
    "            \n",
    "                    # calculate mean of window (offset by floor(window_size/2) because of border)\n",
    "                    Avg_map_r.append(np.nanstd(deramped_r)**2)\n",
    "                    Avg_map_a.append(np.nanstd(deramped_a)**2)\n",
    "                    \n",
    "                    rss = (np.sum(Avg_map_r),np.sum(Avg_map_a))\n",
    "            rss_list.append(rss)\n",
    "        stack_obj.Rss_list = rss_list\n",
    "\n",
    "        return stack_obj.Rss_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "import numpy as np\n",
    "\n",
    "def Run_RSS(stack_obj, indices=[], window_size=5, deramp=True):\n",
    "    # Get stack data\n",
    "    if indices == []:\n",
    "        stack_R = [obj.R_off for obj in stack_obj.Stack]\n",
    "        stack_A = [obj.A_off for obj in stack_obj.Stack]\n",
    "        stack_lons = [getattr(obj, 'Lon_off') for obj in stack_obj.Stack]\n",
    "        stack_lats = [getattr(obj, 'Lat_off') for obj in stack_obj.Stack]\n",
    "    else:\n",
    "        substack = [stack_obj.Stack[i] for i in indices]\n",
    "        stack_R = np.stack([obj.R_off for obj in substack], axis=0)\n",
    "        stack_A = np.stack([obj.A_off for obj in substack], axis=0)\n",
    "        stack_lons = np.stack([getattr(obj, 'Lon_off') for obj in substack])\n",
    "        stack_lats = np.stack([getattr(obj, 'Lat_off') for obj in substack])\n",
    "\n",
    "    rss_list = []\n",
    "\n",
    "    for stack_r, stack_a, stack_lon, stack_lat in zip(stack_R, stack_A, stack_lons, stack_lats):\n",
    "        # Set window size according to stack dimensions\n",
    "        window_shape = (window_size, window_size)\n",
    "\n",
    "        # Use np.lib.stride_tricks.sliding_window_view to divide data into windows\n",
    "        win_data_r = np.lib.stride_tricks.sliding_window_view(stack_r, window_shape)\n",
    "        win_data_a = np.lib.stride_tricks.sliding_window_view(stack_a, window_shape)\n",
    "        win_data_lon = np.lib.stride_tricks.sliding_window_view(stack_lon, window_shape)\n",
    "        win_data_lat = np.lib.stride_tricks.sliding_window_view(stack_lat, window_shape)\n",
    "\n",
    "        # Define shape of multi-kernel averaged map (same as input data), filled with nan\n",
    "        Avg_map_r = np.empty(win_data_r.shape[:-2])\n",
    "        Avg_map_a = np.empty(win_data_a.shape[:-2])\n",
    "\n",
    "        # Per window, calculate RSS\n",
    "        for win_i in range(win_data_r.shape[0]):\n",
    "            if win_i % 5 == 0:\n",
    "                    print('win_i', win_i)\n",
    "            for win_j in range(win_data_r.shape[1]):\n",
    "                win_rng = np.array(win_data_r[win_i, win_j])\n",
    "                win_azi = np.array(win_data_a[win_i, win_j])\n",
    "                lon_win = np.array(win_data_lon[win_i, win_j])\n",
    "                lat_win = np.array(win_data_lat[win_i, win_j])\n",
    "\n",
    "                # Calculate 95% confidence interval\n",
    "                percentiles_r = np.nanpercentile(win_rng, [2.5, 97.5])\n",
    "                percentiles_a = np.nanpercentile(win_azi, [2.5, 97.5])\n",
    "\n",
    "                # Create mask for values outside confidence interval\n",
    "                mask_r = (win_rng < percentiles_r[0]) | (win_rng > percentiles_r[1])\n",
    "                mask_a = (win_azi < percentiles_a[0]) | (win_azi > percentiles_a[1])\n",
    "                mask = (mask_r) |(mask_a)\n",
    "                # Mask data outside confidence interval with nan\n",
    "                win_rng[mask] = np.nan\n",
    "                win_azi[mask] = np.nan\n",
    "                lon_win[mask] = np.nan\n",
    "                lat_win[mask] = np.nan\n",
    "\n",
    "                if deramp and not np.all(np.isnan(win_rng)):\n",
    "                    # Deramp data\n",
    "                    X_data = np.column_stack((lon_win.flatten(), lat_win.flatten()))\n",
    "                    Y_data_r = win_rng.flatten()\n",
    "                    Y_data_a = win_azi.flatten()\n",
    "\n",
    "                    valid_mask_r = ~np.isnan(Y_data_r)\n",
    "                    valid_mask_a = ~np.isnan(Y_data_a)\n",
    "\n",
    "                    X_data_r = X_data[valid_mask_r]\n",
    "                    Y_data_r = Y_data_r[valid_mask_r]\n",
    "\n",
    "                    X_data_a = X_data[valid_mask_a]\n",
    "                    Y_data_a = Y_data_a[valid_mask_a]\n",
    "\n",
    "                    reg_r = linear_model.LinearRegression().fit(X_data_r, Y_data_r)\n",
    "                    deramped_r = win_rng.flatten() - lon_win.flatten() * reg_r.coef_[0] - lat_win.flatten() * reg_r.coef_[1]\n",
    "\n",
    "                    reg_a = linear_model.LinearRegression().fit(X_data_a, Y_data_a)\n",
    "                    deramped_a = win_azi.flatten() - lon_win.flatten() * reg_a.coef_[0] - lat_win.flatten() * reg_a.coef_[1]\n",
    "                else:\n",
    "                    deramped_r = win_rng.flatten()\n",
    "                    deramped_a = win_azi.flatten()\n",
    "\n",
    "                # Calculate mean of window (offset by floor(window_size/2) because of border)\n",
    "                np.append(Avg_map_r,np.nanstd(deramped_r)**2)\n",
    "                np.append(Avg_map_a,np.nanstd(deramped_a)**2)\n",
    "\n",
    "\n",
    "        rss = (np.sum(Avg_map_r), np.sum(Avg_map_a))\n",
    "        rss_list.append(rss)\n",
    "\n",
    "    stack_obj.Rss_list = rss_list\n",
    "    return stack_obj.Rss_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "import numpy as np\n",
    "\n",
    "def Run_RSS(stack_obj, indices= [], window_size=5, deramp=True):\n",
    "    # Get stack data\n",
    "    if indices == []:\n",
    "        stack_R = [obj.R_off for obj in stack_obj.Stack]\n",
    "        stack_A = [obj.A_off for obj in stack_obj.Stack]\n",
    "        stack_lons = [getattr(obj, 'Lon_off') for obj in stack_obj.Stack]\n",
    "        stack_lats = [getattr(obj, 'Lat_off') for obj in stack_obj.Stack]\n",
    "    else:\n",
    "        substack = [stack_obj.Stack[i] for i in indices]\n",
    "        stack_R = np.stack([obj.R_off for obj in substack], axis=0)\n",
    "        stack_A = np.stack([obj.A_off for obj in substack], axis=0)\n",
    "        stack_lons = np.stack([getattr(obj, 'Lon_off') for obj in substack])\n",
    "        stack_lats = np.stack([getattr(obj, 'Lat_off') for obj in substack])\n",
    "\n",
    "    rss_list = []\n",
    "\n",
    "    for stack_r, stack_a, stack_lon, stack_lat in zip(stack_R, stack_A, stack_lons, stack_lats):\n",
    "        # Set window size according to stack dimensions\n",
    "        window_shape = (window_size, window_size)\n",
    "\n",
    "        # Use np.lib.stride_tricks.sliding_window_view to divide data into windows\n",
    "        win_data_r = np.array(np.lib.stride_tricks.sliding_window_view(stack_r, window_shape))\n",
    "        win_data_a = np.array(np.lib.stride_tricks.sliding_window_view(stack_a, window_shape))\n",
    "        win_data_lon = np.array(np.lib.stride_tricks.sliding_window_view(stack_lon, window_shape))\n",
    "        win_data_lat = np.array(np.lib.stride_tricks.sliding_window_view(stack_lat, window_shape))\n",
    "\n",
    "        # Calculate 95% confidence intervals\n",
    "        percentiles_r = np.nanpercentile(win_data_r, [2.5, 97.5], axis=(2, 3), keepdims=True)\n",
    "        percentiles_a = np.nanpercentile(win_data_a, [2.5, 97.5], axis=(2, 3), keepdims=True)\n",
    "\n",
    "        # Create masks for values outside confidence intervals\n",
    "        mask_r = (win_data_r < percentiles_r[0]) | (win_data_r > percentiles_r[1])\n",
    "        mask_a = (win_data_a < percentiles_a[0]) | (win_data_a > percentiles_a[1])\n",
    "        mask = (mask_r) | (mask_a)\n",
    "        # Mask data outside confidence intervals with nan\n",
    "        win_data_r[mask] = np.nan\n",
    "        win_data_a[mask] = np.nan\n",
    "        win_data_lon[mask] = np.nan\n",
    "        win_data_lat[mask] = np.nan\n",
    "\n",
    "        if deramp:\n",
    "            # Deramp data\n",
    "            X_data = np.column_stack((win_data_lon.flatten(), win_data_lat.flatten()))\n",
    "            Y_data_r = win_data_r.flatten()\n",
    "            Y_data_a = win_data_a.flatten()\n",
    "\n",
    "            valid_mask = ~np.isnan(Y_data_r)\n",
    "\n",
    "            X_data = X_data[valid_mask]\n",
    "            Y_data_r = Y_data_r[valid_mask]\n",
    "            Y_data_a = Y_data_a[valid_mask]\n",
    "\n",
    "            reg_r = linear_model.LinearRegression().fit(X_data, Y_data_r)\n",
    "            reg_a = linear_model.LinearRegression().fit(X_data, Y_data_a)\n",
    "\n",
    "            deramped_r = Y_data_r - np.dot(X_data, reg_r.coef_)\n",
    "            deramped_a = Y_data_a - np.dot(X_data, reg_a.coef_)\n",
    "        else:\n",
    "            deramped_r = win_data_r.flatten()\n",
    "            deramped_a = win_data_a.flatten()\n",
    "\n",
    "        # Calculate mean of window (offset by floor(window_size/2) because of border)\n",
    "        avg_map_r = np.nanstd(deramped_r)**2\n",
    "        avg_map_a = np.nanstd(deramped_a)**2\n",
    "\n",
    "        rss_list.append((np.sum(avg_map_r), np.sum(avg_map_a)))\n",
    "\n",
    "    stack_obj.Rss_list = rss_list\n",
    "    return stack_obj.Rss_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rss_list = Run_RSS(datastack,[],5,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.patches import Rectangle\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable # for colorbar scaling\n",
    "from cmcrameri import cm\n",
    "\n",
    "idx_for_plot = [0,2,4,6]\n",
    "map_extent = [0,446,150,550]\n",
    "zoom_extent = [140,240,310,390]\n",
    "\n",
    "substack = [datastack.Stack[i] for i in idx_for_plot]\n",
    "stack_R = np.stack([obj.R_off for obj in substack],axis=0)\n",
    "stack_A = np.stack([obj.A_off for obj in substack],axis=0)\n",
    "\n",
    "plot_data = [stack_R[idx][map_extent[0]:map_extent[1],map_extent[2]:map_extent[3]] for idx in range(len(idx_for_plot))]\n",
    "plot_data.append(MKA_R_off[map_extent[0]:map_extent[1],map_extent[2]:map_extent[3]])\n",
    "plot_data = plot_data + [stack_R[idx][zoom_extent[0]:zoom_extent[1],zoom_extent[2]:zoom_extent[3]] for idx in range(len(idx_for_plot))]\n",
    "plot_data.append(MKA_R_off[zoom_extent[0]:zoom_extent[1],zoom_extent[2]:zoom_extent[3]])\n",
    "plot_data = plot_data + [np.isnan(stack_R[idx][zoom_extent[0]:zoom_extent[1],zoom_extent[2]:zoom_extent[3]]) for idx in range(len(idx_for_plot))]\n",
    "plot_data.append(np.isnan(MKA_R_off)[zoom_extent[0]:zoom_extent[1],zoom_extent[2]:zoom_extent[3]])\n",
    "\n",
    "cmaps = [cm.vik,cm.vik,cm.vik,cm.vik,cm.vik,\n",
    "         cm.vik,cm.vik,cm.vik,cm.vik,cm.vik,\n",
    "         'Greys','Greys','Greys','Greys','Greys',]\n",
    "min_clim = [-vmax,-vmax,-vmax,-vmax,-vmax,\n",
    "            -vmax,-vmax,-vmax,-vmax,-vmax,\n",
    "            0,0,0,0,0,]\n",
    "\n",
    "max_clim = [vmax,vmax,vmax,vmax,vmax,\n",
    "            vmax,vmax,vmax,vmax,vmax,\n",
    "            1,1,1,1,1,]\n",
    "all_data_arrays2 = [datastack.Stack[idx] for idx in idx_for_plot]\n",
    "win_sizes = [str(data.get_window_size()) for data in all_data_arrays2]\n",
    "win_sizes = win_sizes + ['multi-kernel \\naverage']\n",
    "\n",
    "\n",
    "# initiate figure\n",
    "textsize = 28\n",
    "plt.rc('font', size=textsize) \n",
    "fig=plt.figure(figsize=(10,10))\n",
    "gs=GridSpec(3,6) # 3 rows, 5 columns\n",
    "axes = [fig.add_subplot(gs[i,j]) for i in range(3) for j in range(5)]\n",
    "\n",
    "for ax,p_data,cmap,clim_min,clim_max in zip(axes,plot_data,cmaps,min_clim,max_clim):\n",
    "    ax.imshow(p_data,cmap=cmap,vmin=clim_min,vmax=clim_max, interpolation='Nearest')\n",
    "    ax.set_axis_off()\n",
    "    \n",
    "for ax,win_size in zip(axes[0:5],win_sizes):\n",
    "    ax.add_patch(plt.Rectangle((zoom_extent[2]-map_extent[2], zoom_extent[0]-map_extent[0]), zoom_extent[3]-zoom_extent[2], zoom_extent[1]-zoom_extent[0], ls=\"-\", ec=\"k\", fc=\"none\",\n",
    "                           ))\n",
    "    ax.set_title(win_size)\n",
    "\n",
    "fig.tight_layout()\n",
    "cbar_pos = axes[4].get_position()\n",
    " \n",
    "cax = plt.axes([cbar_pos.x0+cbar_pos.width + 0.1, cbar_pos.y0-0.08, 0.01, 2 * cbar_pos.height])      \n",
    "mappable = plt.cm.ScalarMappable(cmap = cm.vik,\n",
    "                                 norm = plt.Normalize(vmin = -vmax, vmax = vmax))\n",
    "cbar = fig.colorbar(mappable, cax, orientation = 'vertical')\n",
    "cbar.set_label('Slant range \\noffset [m]', rotation=90, loc= 'center',labelpad=0)\n",
    "\n",
    "# for ax in axes[0:5]:\n",
    "#     ax.annotate('slant range',xy=(50,50),xytext=(0,-50),textcoords='offset pixels', xycoords='data',\n",
    "#                     arrowprops=dict(facecolor='black',arrowstyle='<-'),horizontalalignment='center',verticalalignment='top',rotation=90)\n",
    "#     ax.annotate('azimuth',xy=(50,50),xytext=(50,0),textcoords='offset pixels' ,xycoords='data',\n",
    "#                     arrowprops=dict(facecolor='black',arrowstyle='<-'),horizontalalignment='left',verticalalignment='center')\n",
    "textsize = 24\n",
    "plt.rc('font', size=textsize) \n",
    "for ax in axes[-10:-5]:\n",
    "    ax.annotate('slant range',xy=(5,5),xytext=(0,-50),textcoords='offset pixels', xycoords='data',\n",
    "                    arrowprops=dict(facecolor='black',arrowstyle='<-',lw=3),horizontalalignment='center',verticalalignment='top',rotation=90)\n",
    "    ax.annotate('azimuth',xy=(5,5),xytext=(50,0),textcoords='offset pixels' ,xycoords='data',\n",
    "                    arrowprops=dict(facecolor='black',arrowstyle='<-',lw=3),horizontalalignment='left',verticalalignment='center')\n",
    "\n",
    "# fig.tight_layout()\n",
    "fig.subplots_adjust(hspace=0.05)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from matplotlib.colors import ListedColormap\n",
    "import rasterio as rio\n",
    "import fiona\n",
    "import geopandas as gpd\n",
    "\n",
    "import json\n",
    "from shapely.geometry import Point, LineString, mapping\n",
    "from functools import partial\n",
    "from shapely.ops import transform\n",
    "\n",
    "\n",
    "# get NDVI data\n",
    "file_name = '../Merapi2021/sentinel2/S2A_MSIL2A_20200821T023551_N0214_R089_T49MDM_20200821T064209.SAFE/GRANULE/L2A_T49MDM_A026970_20200821T025827/IMG_DATA/R10m/T49MDM_20200821T023551_NDVI_10m_WGS84.tif'\n",
    "# with rio.open(file_name) as src:\n",
    "#     band1 = src.read(1)\n",
    "#     print('Band1 has shape', band1.shape)\n",
    "#     height = band1.shape[0]\n",
    "#     width = band1.shape[1]\n",
    "#     cols, rows = np.meshgrid(np.arange(width), np.arange(height))\n",
    "#     xs, ys = rio.transform.xy(src.transform, rows, cols)\n",
    "#     ndvi_lons = np.array(xs)\n",
    "#     ndvi_lats = np.array(ys)\n",
    "#     ndvi_extent = [src.bounds.left,src.bounds.right,src.bounds.bottom,src.bounds.top]\n",
    "\n",
    "\n",
    "# define map region of interest\n",
    "lon_lims = [np.nanmin(lon_off_compare), np.nanmax(lon_off_compare)]\n",
    "lat_lims = [np.nanmin(lat_off_compare), np.nanmax(lat_off_compare)]\n",
    "crop_flag=1\n",
    "\n",
    "# create cropping polygon from ROI\n",
    "if crop_flag:\n",
    "    coords = ((lon_lims[0], lat_lims[0]), (lon_lims[0], lat_lims[1]), (lon_lims[1], lat_lims[1]), (lon_lims[1], lat_lims[0]), (lon_lims[0], lat_lims[0]))\n",
    "    crop_poly = Polygon(coords)\n",
    "    crop_poly_geojson = gpd.GeoSeries([crop_poly])\n",
    "    crop_poly_geojson.to_file('./test_data/test_variability_roi.shp',crs=\"EPSG:4326\")\n",
    "\n",
    "with fiona.open('./test_data/test_variability_roi.shp', \"r\") as shapefile:\n",
    "    shapes = [feature[\"geometry\"] for feature in shapefile]\n",
    "\n",
    "# get data and read coords from first file\n",
    "with rio.open(file_name) as src:\n",
    "    out_image, out_transform = rasterio.mask.mask(src, shapes, crop=True)\n",
    "    out_meta = src.meta\n",
    "    out_meta.update({\"driver\": \"GTiff\",\n",
    "                 \"height\": out_image.shape[1],\n",
    "                 \"width\": out_image.shape[2],\n",
    "                 \"transform\": out_transform})\n",
    "with rasterio.open(\"./test_Data/ndvi_cropped.tif\", \"w\", **out_meta) as dest:\n",
    "    dest.write(out_image)\n",
    "\n",
    "\n",
    "\n",
    "with rio.open(\"./test_Data/ndvi_cropped.tif\") as src:\n",
    "    ndvi_map = src.read(1)\n",
    "    print('Band1 has shape', ndvi_map.shape)\n",
    "    height = ndvi_map.shape[0]\n",
    "    width = ndvi_map.shape[1]\n",
    "    cols, rows = np.meshgrid(np.arange(width), np.arange(height))\n",
    "    xs, ys = rio.transform.xy(src.transform, rows, cols)\n",
    "    ndvi_lons = np.array(xs)\n",
    "    ndvi_lats = np.array(ys)\n",
    "    ndvi_extent = [src.bounds.left,src.bounds.right,src.bounds.bottom,src.bounds.top]\n",
    "\n",
    "\n",
    "x= cm.get_cmap('Blues_r', 135)\n",
    "y= cm.get_cmap('YlGn', 135)\n",
    "z = np.vstack((x(range(135)),\n",
    "                       y(range(135))))\n",
    "ndvi_cmap = ListedColormap(z, name='BlYlGn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib osx\n",
    "\n",
    "# fig, ax = plt.subplots(1,1,figsize=(10,10))\n",
    "# ax.imshow(ndvi_map,cmap=ndvi_cmap,extent=ndvi_extent,vmin=-1,vmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test query point\n",
    "\n",
    "# query points\n",
    "q1 = [110.446216,-7.536389] # stable no veg north\n",
    "q2 = [110.42647,-7.53297] # stable veg north west\n",
    "q3 = [110.4421429,-7.5377992] # L1888\n",
    "q4 = [110.44214,-7.54237] # L1998 large disp\n",
    "q5 = [110.44013,-7.54678] # stable no veg south\n",
    "q6 = [110.44200,-7.53604] # L1956 offset gradient\n",
    "query_points = np.stack((q1,q2,q3,q4,q5,q6))\n",
    "\n",
    "r = 50 # radius of 5 meters around point\n",
    "\n",
    "\n",
    "# original window size 108-52\n",
    "orig_q_mean, orig_q_median, orig_q_std, orig_q_95, coordinate_circles = sm.Post_processing.query_point(lat_off_compare.flatten(),\n",
    "                                                               lon_off_compare.flatten(),\n",
    "                                                               R_off_compare.flatten(),\n",
    "                                                               query_points[:,1],\n",
    "                                                               query_points[:,0],\n",
    "                                                               r)\n",
    "print('\\n')\n",
    "print(f'Range mean for A, B, C: {orig_q_mean}')\n",
    "print(f'Range median for A, B, C: {orig_q_median}')\n",
    "print(f'Range standard deviation for A, B, C: {orig_q_std}')\n",
    "print(f'Range 95\\% confidence interval fro A, B, C: {orig_q_95}')\n",
    "\n",
    "# MKA reuslt\n",
    "MKA_q_mean, MKA_q_median, MKA_q_std, MKA_q_95, coordinate_circles = sm.Post_processing.query_point(lat_off_compare.flatten(),\n",
    "                                                               lon_off_compare.flatten(),\n",
    "                                                               MKA_R_off.flatten(),\n",
    "                                                               query_points[:,1],\n",
    "                                                               query_points[:,0],\n",
    "                                                               r)\n",
    "print('\\n')\n",
    "print(f'Range mean for A, B, C: {MKA_q_mean}')\n",
    "print(f'Range median for A, B, C: {MKA_q_median}')\n",
    "print(f'Range standard deviation for A, B, C: {MKA_q_std}')\n",
    "print(f'Range 95\\% confidence interval fro A, B, C: {MKA_q_95}')\n",
    "\n",
    "# original window size 108-52 azimuth\n",
    "orig_q_mean, orig_q_median, orig_q_std, orig_q_95, coordinate_circles = sm.Post_processing.query_point(lat_off_compare.flatten(),\n",
    "                                                               lon_off_compare.flatten(),\n",
    "                                                               A_off_compare.flatten(),\n",
    "                                                               query_points[:,1],\n",
    "                                                               query_points[:,0],\n",
    "                                                               r)\n",
    "print('\\n')\n",
    "print(f'Azimuth mean for A, B, C: {orig_q_mean}')\n",
    "print(f'Azimuth median for A, B, C: {orig_q_median}')\n",
    "print(f'Azimuth standard deviation for A, B, C: {orig_q_std}')\n",
    "print(f'Azimuth 95\\% confidence interval fro A, B, C: {orig_q_95}')\n",
    "\n",
    "# MKA reuslt\n",
    "MKA_q_mean, MKA_q_median, MKA_q_std, MKA_q_95, coordinate_circles = sm.Post_processing.query_point(lat_off_compare.flatten(),\n",
    "                                                               lon_off_compare.flatten(),\n",
    "                                                               MKA_A_off.flatten(),\n",
    "                                                               query_points[:,1],\n",
    "                                                               query_points[:,0],\n",
    "                                                               r)\n",
    "print('\\n')\n",
    "print(f'Azimuth mean for A, B, C: {MKA_q_mean}')\n",
    "print(f'Azimuth median for A, B, C: {MKA_q_median}')\n",
    "print(f'Azimuth standard deviation for A, B, C: {MKA_q_std}')\n",
    "print(f'Azimuth 95\\% confidence interval fro A, B, C: {MKA_q_95}')\n",
    "\n",
    "\n",
    "# NDVI reuslt\n",
    "ndvi_q_mean, ndvi_q_median, ndvi_q_std, ndvi_q_95, coordinate_circles = sm.Post_processing.query_point(ndvi_lats.flatten(),\n",
    "                                                               ndvi_lons.flatten(),\n",
    "                                                               ndvi_map.flatten(),\n",
    "                                                               query_points[:,1],\n",
    "                                                               query_points[:,0],\n",
    "                                                               r)\n",
    "print('\\n')\n",
    "print(f'mean for A, B, C: {ndvi_q_mean}')\n",
    "print(f'median for A, B, C: {ndvi_q_median}')\n",
    "print(f'standard deviation for A, B, C: {ndvi_q_std}')\n",
    "print(f'95\\% confidence interval fro A, B, C: {ndvi_q_95}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indeces = [0,2,4,6]\n",
    "stats_list, coordinate_circles = datastack.query_point_stack('A_off_vec',\n",
    "                                                             query_points[:,1],\n",
    "                                                             query_points[:,0],\n",
    "                                                             r,\n",
    "                                                             indeces)\n",
    "\n",
    "[q_mean_MKA, q_median_MKA, q_std_MKA, q_95_MKA], coordinate_circles = datastack.query_point_MKA('MKA_A_off',\n",
    "                                                                                                 query_points[:,1],\n",
    "                                                                                                 query_points[:,0],\n",
    "                                                                                                 r)                                                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(stats_list)\n",
    "# print(q_mean_MKA, q_median_MKA, q_std_MKA, q_95_MKA)\n",
    "print(MKA_q_mean, MKA_q_median, MKA_q_std, MKA_q_95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make plot for comparison\n",
    "# 1 original input mid window size\n",
    "# 2 outlier removed-mka result\n",
    "# 3 ndvi\n",
    "from cmcrameri import cm\n",
    "from matplotlib_scalebar.scalebar import ScaleBar\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "\n",
    "data2plot = [R_off_compare,MKA_R_off,ndvi_map]\n",
    "lon2plot = [lon_off_compare,lon_off_compare,ndvi_lons]\n",
    "lat2plot = [lat_off_compare,lat_off_compare,ndvi_lats]\n",
    "cmaps = [cm.vik,cm.vik,ndvi_cmap]\n",
    "vmins = [-3,-3,-1]\n",
    "vmaxs = [3,3,1]\n",
    "cbar_labels = ['Slant range\\noffset [m]', 'Slant range\\noffset [m]', 'NDVI [-]']\n",
    "lon_lims = [110.42, 110.45]\n",
    "lat_lims = [-7.55, -7.53]\n",
    "# q1 = [110.446216,-7.536389]\n",
    "# q2 = [110.427882,-7.530558]\n",
    "# q3 = [110.4421429,-7.5377992]\n",
    "\n",
    "distance_meters = sm.plot.get_1deg_dist()\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(3,1,figsize=(4,12))\n",
    "for i,(data,lon_p,lat_p,cmap,vmin,vmax,cbar_label) in enumerate(zip(data2plot,lon2plot,lat2plot,cmaps,vmins,vmaxs,cbar_labels)):\n",
    "    plot_extent = [np.nanmin(lon_p),np.nanmax(lon_p),np.nanmin(lat_p),np.nanmax(lat_p)]\n",
    "    plot_data = ax[i].hexbin(lon_p.flatten(),lat_p.flatten(),C=data.flatten(),gridsize=500,cmap=cmap,vmin=vmin,vmax=vmax)\n",
    "    ax[i].plot(coordinate_circles[0][:,0],coordinate_circles[0][:,1],color='Black',linewidth=3)\n",
    "    ax[i].plot(coordinate_circles[1][:,0],coordinate_circles[1][:,1],color='Black',linewidth=3)\n",
    "    ax[i].plot(coordinate_circles[2][:,0],coordinate_circles[2][:,1],color='Black',linewidth=3)\n",
    "    ax[i].plot(coordinate_circles[3][:,0],coordinate_circles[3][:,1],color='Black',linewidth=3)\n",
    "    ax[i].plot(coordinate_circles[4][:,0],coordinate_circles[4][:,1],color='Black',linewidth=3)\n",
    "    ax[i].plot(coordinate_circles[5][:,0],coordinate_circles[5][:,1],color='Black',linewidth=3)\n",
    "    ax[i].set_xlim(lon_lims)\n",
    "    ax[i].set_ylim(lat_lims)\n",
    "    ax[i].set_aspect('equal', 'box')\n",
    "    ax[i].add_artist(ScaleBar(distance_meters,location='lower left'))\n",
    "    ax[i].set_axis_off()\n",
    "    cbar = plt.colorbar(plot_data,ax=ax[i])\n",
    "    cbar.set_label(cbar_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make plot for comparison\n",
    "# 1 original input mid window size\n",
    "# 2 outlier removed-mka result\n",
    "# 3 ndvi\n",
    "from cmcrameri import cm\n",
    "from matplotlib_scalebar.scalebar import ScaleBar\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "\n",
    "data2plot = [R_off_compare,MKA_A_off]\n",
    "lon2plot = [lon_off_compare,lon_off_compare,lon_off_compare,lon_off_compare]\n",
    "lat2plot = [lat_off_compare,lat_off_compare,lon_off_compare,lon_off_compare]\n",
    "cmaps = [cm.vik,cm.vik,cm.vik,cm.vik]\n",
    "vmins = [-3,-3,-3,-3]\n",
    "vmaxs = [3,3,3,3]\n",
    "cbar_labels = ['Slant range\\noffset [m]', 'Azimuth\\noffset [m]', 'Slant range\\noffset [m]', 'Azimuth\\noffset [m]',]\n",
    "lon_lims = [110.42, 110.45]\n",
    "lat_lims = [-7.55, -7.53]\n",
    "# q1 = [110.446216,-7.536389]\n",
    "# q2 = [110.427882,-7.530558]\n",
    "# q3 = [110.4421429,-7.5377992]\n",
    "\n",
    "distance_meters = sm.plot.get_1deg_dist()\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(2,2,figsize=(12,12))\n",
    "\n",
    "for (i,j,data,lon_p,lat_p,cmap,vmin,vmax,cbar_label) in zip([0,0,1,1],[0,1,0,1],data2plot,lon2plot,lat2plot,cmaps,vmins,vmaxs,cbar_labels):\n",
    "    plot_extent = [np.nanmin(lon_p),np.nanmax(lon_p),np.nanmin(lat_p),np.nanmax(lat_p)]\n",
    "    plot_data = ax[i,j].hexbin(lon_p.flatten(),lat_p.flatten(),C=data.flatten(),gridsize=500,cmap=cmap,vmin=vmin,vmax=vmax)\n",
    "    # ax[i].plot(coordinate_circles[0][:,0],coordinate_circles[0][:,1],color='Black',linewidth=3)\n",
    "    # ax[i].plot(coordinate_circles[1][:,0],coordinate_circles[1][:,1],color='Black',linewidth=3)\n",
    "    # ax[i].plot(coordinate_circles[2][:,0],coordinate_circles[2][:,1],color='Black',linewidth=3)\n",
    "    # ax[i].plot(coordinate_circles[3][:,0],coordinate_circles[3][:,1],color='Black',linewidth=3)\n",
    "    # ax[i].plot(coordinate_circles[4][:,0],coordinate_circles[4][:,1],color='Black',linewidth=3)\n",
    "    # ax[i].plot(coordinate_circles[5][:,0],coordinate_circles[5][:,1],color='Black',linewidth=3)\n",
    "    ax[i,j].set_xlim(lon_lims)\n",
    "    ax[i,j].set_ylim(lat_lims)\n",
    "    ax[i,j].set_aspect('equal', 'box')\n",
    "    ax[i,j].add_artist(ScaleBar(distance_meters,location='lower left'))\n",
    "    ax[i,j].set_axis_off()\n",
    "    cbar = plt.colorbar(plot_data,ax=ax[i,j])\n",
    "    cbar.set_label(cbar_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.close('all')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
