{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "make figure showing:\n",
    "\n",
    "- Merapi true colour\n",
    "- Merapi slope\n",
    "- Merapi shadow overlay map\n",
    "- interferogram\n",
    "- pixel offset range and azimuth\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import external packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numba\n",
    "from numba import vectorize\n",
    "import glob # for file search\n",
    "import copy\n",
    "import os # operating system stuff\n",
    "import re # regex\n",
    "import fastparquet # fast read/write for large data structures\n",
    "import sklearn.preprocessing as pre # for data normalisation\n",
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "import geopandas as gpd\n",
    "import rasterio as rio\n",
    "import rasterio.mask\n",
    "from rasterio.plot import plotting_extent\n",
    "from shapely.geometry import Polygon\n",
    "from shapely.geometry.point import Point\n",
    "import pyproj\n",
    "from pyproj import CRS\n",
    "from inpoly import inpoly2 # for fast inpolygon checks\n",
    "import utm\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "import matplotlib.dates as mdates\n",
    "from matplotlib import cm as mpl_cm\n",
    "from matplotlib import colors as mcolors \n",
    "import matplotlib.image as mplimg\n",
    "\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable # for colorbar scaling\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "from matplotlib_scalebar.scalebar import ScaleBar\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "\n",
    "import seaborn as sns\n",
    "from matplotlib import rc_file_defaults\n",
    "rc_file_defaults()\n",
    "# sns.set(style=None, color_codes=True)\n",
    "\n",
    "from shapely.geometry import Polygon\n",
    "from shapely.geometry.point import Point\n",
    "import datetime\n",
    "\n",
    "import configparser\n",
    "\n",
    "from cmcrameri import cm # for scientific colourmaps\n",
    "\n",
    "###########################\n",
    "# import main local package\n",
    "import SPOTSAR_main as sm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "################ Define user INPUTS #######################\n",
    "######## please edit the values of this block only ########\n",
    "###########################################################\n",
    "\n",
    "# define hillshade file\n",
    "HS_FILE = './test_data/DEM/TDX_Merapi_WGS84_HS.tif'\n",
    "\n",
    "# Indonesia shapefile\n",
    "IND_COAST = './test_data/DEM/IDN_adm/IDN_adm0.shp' \n",
    "\n",
    "# define lon and lat files\n",
    "LON_FILE = './test_data/CSK_dsc/geo2/20200910.lon'\n",
    "LAT_FILE = './test_data/CSK_dsc/geo2/20200910.lat'\n",
    "\n",
    "S1_LON_FILE = './test_data/S1_dsc/geo/20200616.lon'\n",
    "S1_LAT_FILE = './test_data/S1_dsc/geo/20200616.lat'\n",
    "\n",
    "# define parameter text file\n",
    "PARAM_FILE = './test_data/CSK_dsc/params.txt'\n",
    "\n",
    "# DEM, SLOPE and NDVI file\n",
    "DEM_FILE = './test_data/DEM/TDX_Merapi_WGS84_5m.tif'\n",
    "SLOPE_FILE = './test_data/DEM/TDX_Merapi_WGS84_5m_slope.tif'\n",
    "NDVI_FILE = '/Users/markbemelmans/Documents/PhD/projects/Merapi2021/sentinel2/Sentinel_NDVI_WGS84_v2.tif'\n",
    "TRUE_COL_FILE = '/Users/markbemelmans/Documents/PhD/projects/Merapi2021/sentinel2/Sentinel_true_color_WGS84.tif'\n",
    "LS_MAP_FILE = '/Users/markbemelmans/Documents/PhD/projects/Merapi2021/CSK/dsc1/c20200910.ls_map_dem_seg.png'\n",
    "IFG_FILE = '/Users/markbemelmans/Documents/PhD/projects/Merapi2021/CSK/dsc1/example_ifgs/20210217_20210218_img.diff.gc.tif'\n",
    "# PWR_FILE = './test_data/CSK_dsc/rmlis/c20200910.rmli.gc.tif'\n",
    "PWR_FILE = './test_data/CSK_dsc/rmlis/c20200910.crop.rmli.ras'\n",
    "\n",
    "S1_IFG_FILE = './test_data/S1_dsc/20200908_20201119/20200908_20201119.diff.gc.tif'\n",
    "S1_SPOT_FILE = './test_data/S1_dsc/20200908_20201119/disp_20200908_20201119.txt'\n",
    "S1_SPOT_FILE_CCS = './test_data/S1_dsc/20200908_20201119/20200908_20201119.ccs'\n",
    "# S1_PWR_FILE = './test_data/S1_dsc/20200908_20201119/20200908.rmli.gc.tif'\n",
    "S1_PWR_FILE = './test_data/S1_dsc/20200908_20201119/20200908.crop.rmli.ras'\n",
    "# define map region of interest\n",
    "lon_lims = [110.425, 110.45]\n",
    "lat_lims = [-7.555, -7.535]\n",
    "\n",
    "\n",
    "\n",
    "# define colour range {min max} (min = -max)\n",
    "vmax = 3 # range of colourscale in meters\n",
    "\n",
    "# define file names for data, lon and lat\n",
    "DIRECTORY_PATH = \"./test_data/CSK_dsc/DISP_txt2/\"\n",
    "# define path to ccp and ccs files\n",
    "DIRECTORY_PATH_CCS = \"./test_data/CSK_dsc/CCS2/\"\n",
    "\n",
    "# Set the regular expression pattern to match the file names\n",
    "PATTERN1 = r\"^c20210217_c20210218_disp_[0-9]+_[0-9]+\\.txt$\"\n",
    "\n",
    "# Set the regular expression pattern to match the ccs file names\n",
    "PATTERN_CCS1 = r\"^c20210217_c20210218_ccs_[0-9]+_[0-9]+$\"\n",
    "\n",
    "# open hillshade file and re-order offset and CCS files\n",
    "\n",
    "# open hill shade file with rasterio\n",
    "DEM_HS = rio.open(HS_FILE)\n",
    "SHADING = DEM_HS.read(1,masked=True) # rasterio bands are indexed from 1\n",
    "\n",
    "# extract DEM extent\n",
    "DEM_EXTENT=[DEM_HS.bounds.left,DEM_HS.bounds.right,DEM_HS.bounds.bottom,DEM_HS.bounds.top]\n",
    "\n",
    "# read ls map\n",
    "ls_map = mplimg.imread(LS_MAP_FILE)\n",
    "\n",
    "# get world borders via geopandas\n",
    "\n",
    "world = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))\n",
    "\n",
    "# read parameters from text file\n",
    "config = configparser.ConfigParser()\n",
    "config.read(PARAM_FILE)\n",
    "WIDTH = int(config.get('params', 'width'))\n",
    "LINES = int(config.get('params', 'lines'))\n",
    "WIDTH_CCS = int(config.get('params', 'width_ccs'))\n",
    "LINES_CCS = int(config.get('params', 'lines_ccs'))\n",
    "R_START = int(config.get('params', 'r_start'))\n",
    "A_START = int(config.get('params', 'a_start'))\n",
    "R_STEP = int(config.get('params', 'r_step'))\n",
    "A_STEP = int(config.get('params', 'a_step'))\n",
    "HEADING = float(config.get('params', 'heading'))\n",
    "MEAN_INC = float(config.get('params', 'mean_inc'))\n",
    "\n",
    "S1_WIDTH = 24910\n",
    "S1_LINES = 4185\n",
    "S1_PWR_WIDTH = 2310\n",
    "S1_PWR_LINES = 1215\n",
    "S1_WIDTH_CCS = 262\n",
    "S1_LINES_CCS = 546\n",
    "S1_R_START = 2804\n",
    "S1_A_START = 1743\n",
    "S1_R_STEP = 10\n",
    "S1_A_STEP = 2\n",
    "S1_HEADING = 192.0799295\n",
    "S1_MEAN_INC = 39.1333"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['c20210217_c20210218_disp_58_28.txt', 'c20210217_c20210218_disp_99_48.txt', 'c20210217_c20210218_disp_140_68.txt', 'c20210217_c20210218_disp_182_88.txt', 'c20210217_c20210218_disp_224_108.txt']\n",
      "['c20210217_c20210218_ccs_58_28', 'c20210217_c20210218_ccs_99_48', 'c20210217_c20210218_ccs_140_68', 'c20210217_c20210218_ccs_182_88', 'c20210217_c20210218_ccs_224_108']\n"
     ]
    }
   ],
   "source": [
    "# reorder file using Post_processing.reorder_files\n",
    "matching_files1 = sm.Post_processing.reorder_files(DIRECTORY_PATH,PATTERN1,0)\n",
    "matching_files_ccs1 = sm.Post_processing.reorder_files(DIRECTORY_PATH_CCS,PATTERN_CCS1,0)\n",
    "print(matching_files1)\n",
    "print(matching_files_ccs1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from files into class multi-kernel\n",
    "example_pairs = []\n",
    "for (matching_files,matching_files_ccs) in zip([matching_files1],[matching_files_ccs1]):\n",
    "    datastack = sm.Post_processing.MultiKernel(DIRECTORY_PATH,\n",
    "                                            matching_files,\n",
    "                                            DIRECTORY_PATH_CCS,\n",
    "                                            matching_files_ccs,\n",
    "                                            LAT_FILE,\n",
    "                                            LON_FILE,\n",
    "                                            HEADING,\n",
    "                                            MEAN_INC,\n",
    "                                            LINES_CCS,\n",
    "                                            WIDTH_CCS)\n",
    "    # We need to assign some data not stored in the disp.txt files.\n",
    "    datastack.get_params_from_file_name()\n",
    "    datastack.get_latlon_from_file(WIDTH)\n",
    "    datastack.add_lat_lon_to_data(R_START,A_START)\n",
    "    datastack.crop_stack_ccs(R_STEP,A_STEP)\n",
    "    # the object datastack now has several attributes associated with the whole dataset (e.g., date1, date2, heading)\n",
    "    # Next we add all the offset data (disp.txt) to the stack\n",
    "    stacked_data = datastack.assign_data_to_stack(R_STEP,A_STEP)\n",
    "    # The attribute 'Stack' we find a list of single-kernel objects which contain the actual offset data, ccp and ccs data and the coordinates.\n",
    "\n",
    "    # add stack to list\n",
    "    example_pairs.append(datastack)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         0     1      2      3      4      5      6      7       8         9   \\\n",
      "0      3294  1909 -0.100  0.064 -0.121 -0.026  0.404  0.049   1.266 -7.497390   \n",
      "1      3304  1909 -0.095  0.076 -0.121 -0.026  0.398  0.060   1.425 -7.497278   \n",
      "2      3314  1909 -0.109  0.079 -0.120 -0.026  0.389  0.027   1.477 -7.497250   \n",
      "3      3284  1911 -0.117  0.047 -0.121 -0.026  0.412  0.009   1.016 -7.497804   \n",
      "4      3294  1911 -0.104  0.061 -0.121 -0.026  0.407  0.040   1.214 -7.497621   \n",
      "...     ...   ...    ...    ...    ...    ...    ...    ...     ...       ...   \n",
      "66633  4824  2669 -0.900 -0.582 -0.187  0.016  0.138 -1.660  -8.406 -7.580797   \n",
      "66634  4834  2669  0.428 -0.716 -0.189  0.016  0.127  1.435 -10.277 -7.580739   \n",
      "66635  4794  2671 -0.303 -0.210 -0.183  0.016  0.181 -0.278  -3.179 -7.581275   \n",
      "66636  4804  2671 -0.435 -0.375 -0.185  0.016  0.159 -0.582  -5.499 -7.581219   \n",
      "66637  4814  2671 -0.788 -0.502 -0.186  0.016  0.141 -1.402  -7.280 -7.581149   \n",
      "\n",
      "               10  \n",
      "0      110.485886  \n",
      "1      110.485435  \n",
      "2      110.485001  \n",
      "3      110.486595  \n",
      "4      110.485786  \n",
      "...           ...  \n",
      "66633  110.416496  \n",
      "66634  110.416176  \n",
      "66635  110.417442  \n",
      "66636  110.417152  \n",
      "66637  110.416855  \n",
      "\n",
      "[66638 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## Sentinel-1 offset tracking pair\n",
    "\n",
    "S1_data = pd.read_csv(S1_SPOT_FILE, header  =None, sep = '\\s+')\n",
    "\n",
    "# get latitude and longitude data from file\n",
    "S1_lon_vec = np.fromfile(S1_LON_FILE, dtype='>f', count=-1)\n",
    "S1_lat_vec = np.fromfile(S1_LAT_FILE, dtype='>f', count=-1)\n",
    "# set 0,0 coordinates to nan\n",
    "S1_lon_vec[S1_lon_vec == 0] = np.nan\n",
    "S1_lat_vec[S1_lat_vec == 0] = np.nan\n",
    "# get number of lines in lat lon files\n",
    "lines_ll = S1_lon_vec.shape[0]/S1_WIDTH\n",
    "# reshape tomatrix for index referencing\n",
    "S1_LON = np.reshape(S1_lon_vec,[int(lines_ll),S1_WIDTH])\n",
    "S1_LAT = np.reshape(S1_lat_vec,[int(lines_ll),S1_WIDTH]) \n",
    "\n",
    "S1_data[9]  = S1_LAT[S1_data[1],S1_data[0]]\n",
    "S1_data[10] = S1_LON[S1_data[1],S1_data[0]]\n",
    "\n",
    "print(S1_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data ./test_data/DEM/TDX_Merapi_WGS84_5m.tif has shape (2028, 1672)\n",
      "Data ./test_data/DEM/TDX_Merapi_WGS84_5m_slope.tif has shape (2028, 1672)\n",
      "Data ./test_Data/ndvi_cropped.tif has shape (171, 141)\n",
      "Data ./test_Data/TRUE_COL_cropped.tif has shape (1017, 838, 3)\n",
      "Data /Users/markbemelmans/Documents/PhD/projects/Merapi2021/CSK/dsc1/example_ifgs/20210217_20210218_img.diff.gc.tif has shape (10171, 8384, 3)\n",
      "Data ./test_data/S1_dsc/20200908_20201119/20200908_20201119.diff.gc.tif has shape (10171, 8384, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/m9/32v45xkn4zx6js6htb1prb2r0000gn/T/ipykernel_87752/2983929118.py:120: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
      "  x= mpl_cm.get_cmap('Blues_r', 135)\n",
      "/var/folders/m9/32v45xkn4zx6js6htb1prb2r0000gn/T/ipykernel_87752/2983929118.py:121: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
      "  y= mpl_cm.get_cmap('YlGn', 135)\n"
     ]
    }
   ],
   "source": [
    "import fiona\n",
    "from matplotlib.colors import ListedColormap\n",
    "from matplotlib import cm as mpl_cm\n",
    "## find nearest elevation, slope, and NDVI values\n",
    "\n",
    "\n",
    "def read_tiff(filename,n_bands):\n",
    "    with rio.open(filename) as src:\n",
    "\n",
    "        values = [src.read(i+1) for i in range(n_bands)]\n",
    "        if n_bands > 1:\n",
    "            values_stack = np.stack(values,axis=-1)\n",
    "        else:\n",
    "            values_stack = values[0]\n",
    "        print(f'Data {filename} has shape', values_stack.shape)\n",
    "        height = values_stack.shape[0]\n",
    "        width = values_stack.shape[1]\n",
    "        cols, rows = np.meshgrid(np.arange(width), np.arange(height))\n",
    "        xs, ys = rio.transform.xy(src.transform, rows, cols)\n",
    "        lons = np.array(xs)\n",
    "        lats = np.array(ys)\n",
    "        extent = [src.bounds.left,src.bounds.right,src.bounds.bottom,src.bounds.top]\n",
    "    return values_stack, lons, lats, extent \n",
    "\n",
    "\n",
    "# load indonesia borders\n",
    "ind_coastlines = gpd.read_file(IND_COAST)\n",
    "\n",
    "\n",
    "DEM_heights, DEM_lons, DEM_lats, DEM_extent = read_tiff(DEM_FILE,1)\n",
    "DEM_slope, slope_lons, slope_lats, slope_extent = read_tiff(SLOPE_FILE,1)\n",
    "\n",
    "## NDVI open and crop data to DEM extent\n",
    "# define map region of interest\n",
    "lon_lims = [np.nanmin(DEM_lons), np.nanmax(DEM_lons)]\n",
    "lat_lims = [np.nanmin(DEM_lats), np.nanmax(DEM_lats)]\n",
    "crop_flag=1\n",
    "\n",
    "# create cropping polygon from ROI\n",
    "if crop_flag:\n",
    "    coords = ((lon_lims[0], lat_lims[0]), (lon_lims[0], lat_lims[1]), (lon_lims[1], lat_lims[1]), (lon_lims[1], lat_lims[0]), (lon_lims[0], lat_lims[0]))\n",
    "    crop_poly = Polygon(coords)\n",
    "    crop_poly_geojson = gpd.GeoSeries([crop_poly])\n",
    "    crop_poly_geojson.to_file('./test_data/crop_ndvi_poly.shp',crs=\"EPSG:4326\")\n",
    "\n",
    "\n",
    "with fiona.open('./test_data/crop_ndvi_poly.shp', \"r\") as shapefile:\n",
    "    shapes = [feature[\"geometry\"] for feature in shapefile]\n",
    "\n",
    "# get data and read coords from first file\n",
    "with rio.open(NDVI_FILE) as src:\n",
    "    out_image, out_transform = rasterio.mask.mask(src, shapes, crop=True)\n",
    "    out_meta = src.meta\n",
    "    out_meta.update({\"driver\": \"GTiff\",\n",
    "                 \"height\": out_image.shape[1],\n",
    "                 \"width\": out_image.shape[2],\n",
    "                 \"transform\": out_transform})\n",
    "with rasterio.open(\"./test_Data/ndvi_cropped.tif\", \"w\", **out_meta) as dest:\n",
    "    dest.write(out_image)\n",
    "\n",
    "NDVI, ndvi_lons, ndvi_lats, ndvi_extent = read_tiff(\"./test_Data/ndvi_cropped.tif\",1)\n",
    "\n",
    "\n",
    "with rio.open(TRUE_COL_FILE) as src:\n",
    "    out_image, out_transform = rasterio.mask.mask(src, shapes, crop=True)\n",
    "    out_meta = src.meta\n",
    "    out_meta.update({\"driver\": \"GTiff\",\n",
    "                 \"height\": out_image.shape[1],\n",
    "                 \"width\": out_image.shape[2],\n",
    "                 \"transform\": out_transform})\n",
    "with rasterio.open(\"./test_Data/TRUE_COL_cropped.tif\", \"w\", **out_meta) as dest:\n",
    "    dest.write(out_image)\n",
    "\n",
    "TRUE_COL, TRUE_COL_lons, TRUE_COL_lats, TRUE_COL_extent = read_tiff(\"./test_Data/TRUE_COL_cropped.tif\",3)\n",
    "CSK_IFG, CSK_IFG_lons, CSK_IFG_lats, CSK_IFG_extent = read_tiff(IFG_FILE,3)\n",
    "# CSK_PWR, CSK_PWR_lons, CSK_PWR_lats, CSK_PWR_extent = read_tiff(PWR_FILE,1)\n",
    "# with rio.open(PWR_FILE) as src:\n",
    "#     CSK_PWR = src.read(1)\n",
    "\n",
    "CSK_PWR = plt.imread(PWR_FILE)\n",
    "\n",
    "\n",
    "S1_IFG, S1_IFG_lons, S1_IFG_lats, S1_IFG_extent = read_tiff(S1_IFG_FILE,3)\n",
    "# S1_PWR, S1_PWR_lons, S1_PWR_lats, S1_PWR_extent = read_tiff(S1_PWR_FILE,1)\n",
    "# with rio.open(S1_PWR_FILE) as src:\n",
    "#     S1_PWR = src.read(1)\n",
    "S1_PWR = plt.imread(S1_PWR_FILE)\n",
    "\n",
    "# with rio.open(\"./test_Data/TRUE_COL_cropped.tif\") as src:\n",
    "#     TRUE_COL_1 = src.read(1)\n",
    "#     TRUE_COL_2 = src.read(2)\n",
    "#     TRUE_COL_3 = src.read(3)\n",
    "#     print('Band1 has shape', TRUE_COL_1.shape)\n",
    "#     height = NDVI.shape[0]\n",
    "#     width = NDVI.shape[1]\n",
    "#     cols, rows = np.meshgrid(np.arange(width), np.arange(height))\n",
    "#     xs, ys = rio.transform.xy(src.transform, rows, cols)\n",
    "#     TRUE_COL_lons = np.array(xs)\n",
    "#     TRUE_COL_lats = np.array(ys)\n",
    "#     TRUE_COL_extent = [src.bounds.left,src.bounds.right,src.bounds.bottom,src.bounds.top]\n",
    "\n",
    "# TRUE_COL = np.stack((TRUE_COL_1,TRUE_COL_2,TRUE_COL_3),axis=-1)\n",
    "\n",
    "\n",
    "# with rio.open(IFG_FILE) as src:\n",
    "#     IFG_1 = src.read(1)\n",
    "#     IFG_2 = src.read(2)\n",
    "#     IFG_3 = src.read(3)\n",
    "#     print('Band1 has shape', IFG_1.shape)\n",
    "#     height = DEM_heights.shape[0]\n",
    "#     width = DEM_heights.shape[1]\n",
    "#     cols, rows = np.meshgrid(np.arange(width), np.arange(height))\n",
    "#     xs, ys = rio.transform.xy(src.transform, rows, cols)\n",
    "#     IFG_lons = np.array(xs)\n",
    "#     IFG_lats = np.array(ys)\n",
    "#     IFG_extent = [src.bounds.left,src.bounds.right,src.bounds.bottom,src.bounds.top]\n",
    "\n",
    "# IFG = np.stack((IFG_1,IFG_2,IFG_3),axis=-1)\n",
    "\n",
    "x= mpl_cm.get_cmap('Blues_r', 135)\n",
    "y= mpl_cm.get_cmap('YlGn', 135)\n",
    "z = np.vstack((x(range(135)),\n",
    "                       y(range(135))))\n",
    "ndvi_cmap = ListedColormap(z, name='BlYlGn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## overview figure\n",
    "\n",
    "# 1   2   3  \n",
    "# 4   5   6   \n",
    "# 7   8   9   \n",
    "\n",
    "# 1: True colour S2\n",
    "# 2: CSK Amplitude\n",
    "# 3: S1 Amplitude\n",
    "# 4: CSK ifg\n",
    "# 5: CSK range off\n",
    "# 6: CSK azi off\n",
    "# 7: S1 ifg\n",
    "# 8: S1 range off\n",
    "# 9: S1 azi off\n",
    "\n",
    "%matplotlib osx\n",
    "\n",
    "from matplotlib.patches import Rectangle\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "# make figure\n",
    "grid_size = 1000\n",
    "cmap=cm.vik\n",
    "clims = [-3, 3]\n",
    "lon_lims = [110.425, 110.46]\n",
    "lat_lims = [-7.555, -7.515]\n",
    "orientation = 'vertical'\n",
    "\n",
    "CSK_obj = example_pairs[0].Stack[1]\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "gs = GridSpec(3, 3, figure=fig)\n",
    "ax00 = fig.add_subplot(gs[0, 0]) # Merapi true colour with inset\n",
    "ax01 = fig.add_subplot(gs[0, 1]) # CSK amplitude (with summit inset?)\n",
    "ax02 = fig.add_subplot(gs[0, 2]) # S1 amplitude (with summit inset?)\n",
    "ax10 = fig.add_subplot(gs[1, 0]) # CSK ifg\n",
    "ax11 = fig.add_subplot(gs[1, 1]) # CSK range off\n",
    "ax12 = fig.add_subplot(gs[1, 2]) # CSK azi off\n",
    "ax20 = fig.add_subplot(gs[2, 0]) # S1 ifg\n",
    "ax21 = fig.add_subplot(gs[2, 1]) # S1 range off\n",
    "ax22 = fig.add_subplot(gs[2, 2]) # S1 azi off\n",
    "\n",
    "\n",
    "\n",
    "ax00.imshow(TRUE_COL,extent=TRUE_COL_extent)\n",
    "ax00_1 = ax00.inset_axes([0.5,0.75,0.5,0.25])\n",
    "ax00_1.add_patch(Rectangle((90,-15),55,25,color='white'))\n",
    "# world.plot(ax=ax00_1,color='lightgrey',edgecolor='black')\n",
    "ind_coastlines.plot(ax=ax00_1,color='lightgrey',edgecolor='black')\n",
    "ax00_1.scatter(110.4,-7.54,s=5,c='red')\n",
    "ax00_1.set_aspect('equal','box')\n",
    "ax00_1.set_xlim((105,117))\n",
    "ax00_1.set_ylim((-9,-5))\n",
    "ax00_1.set_axis_off()\n",
    "\n",
    "\n",
    "# S1_PWR_map = ax01.imshow(S1_PWR[250:1000,750:2000],cmap='Greys')\n",
    "# ax01_1 = inset_axes(ax01,width='50%',height='50%',loc='upper right')\n",
    "# ax01_1.imshow(S1_PWR[520:625,1100:1310],cmap='Greys')\n",
    "ax01.imshow(S1_PWR[470:675,1075:1335],cmap='Greys')\n",
    "\n",
    "\n",
    "# CSK_PWR_map = ax02.imshow(CSK_PWR,cmap='Greys')\n",
    "# ax02_1 = inset_axes(ax02,width='50%',height='50%',loc='upper right')\n",
    "# ax02_1.imshow(CSK_PWR[3900:5210,1940:3270],cmap='Greys')\n",
    "ax02.imshow(CSK_PWR[3400:5710,1440:3770],cmap='Greys')\n",
    "# ax02_1 = inset_axes(ax02,width='50%',height='50%',loc='lower left')\n",
    "# ax02_1.imshow(CSK_PWR[4100:4300,2190:2390],cmap='Greys')\n",
    "\n",
    "ax10.imshow(S1_IFG,extent=S1_IFG_extent)\n",
    "S1_r_off_map = ax11.hexbin(S1_data[10],S1_data[9],C=S1_data[7],gridsize=grid_size,cmap=cmap,vmin=clims[0],vmax=clims[1])\n",
    "S1_a_off_map = ax12.hexbin(S1_data[10],S1_data[9],C=S1_data[8],gridsize=grid_size,cmap=cmap,vmin=clims[0],vmax=clims[1])\n",
    "\n",
    "ax20.imshow(CSK_IFG,extent=CSK_IFG_extent)\n",
    "\n",
    "CSK_r_off_map = ax21.hexbin(CSK_obj.Lon_off.flatten(),CSK_obj.Lat_off.flatten(),C=CSK_obj.R_off.flatten(),gridsize=grid_size,cmap=cmap,vmin=clims[0],vmax=clims[1])\n",
    "# plt.colorbar(r_off_map,label='range offset [m]',orientation=orientation)\n",
    "\n",
    "CSK_a_off_map = ax22.hexbin(CSK_obj.Lon_off.flatten(),CSK_obj.Lat_off.flatten(),C=CSK_obj.A_off.flatten(),gridsize=grid_size,cmap=cmap,vmin=clims[0],vmax=clims[1])\n",
    "# plt.colorbar(a_off_map,label='azimuth offset [m]',orientation=orientation)\n",
    "\n",
    "\n",
    "for a in [ax00,ax10,ax11,ax12,ax20,ax21,ax22]:\n",
    "    a.set_aspect('equal','box')\n",
    "    a.set_xlim(lon_lims)\n",
    "    a.set_ylim(lat_lims)\n",
    "    a.add_artist(ScaleBar(sm.plot.get_1deg_dist(),location='upper left'))\n",
    "\n",
    "for a in [ax00,ax01,ax02,ax10,ax11,ax12,ax20,ax21,ax22]:\n",
    "    a.set_axis_off()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[110.425, 110.46] [-7.555, -7.515]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-21 16:06:00.545 python[86118:1940784] +[CATransaction synchronize] called within transaction\n",
      "2023-09-21 16:06:07.086 python[86118:1940784] +[CATransaction synchronize] called within transaction\n",
      "2023-09-21 16:06:08.220 python[86118:1940784] +[CATransaction synchronize] called within transaction\n"
     ]
    }
   ],
   "source": [
    "%matplotlib osx\n",
    "\n",
    "from matplotlib.patches import Rectangle\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "# make figure\n",
    "grid_size = 1000\n",
    "cmap=cm.vik\n",
    "clims = [-3, 3]\n",
    "lon_lims = [110.425, 110.46]\n",
    "lat_lims = [-7.555, -7.515]\n",
    "orientation = 'vertical'\n",
    "\n",
    "obj = example_pairs[0].Stack[1]\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "gs = GridSpec(2, 4, figure=fig)\n",
    "ax00 = fig.add_subplot(gs[0, 0]) # Merapi true colour with inset\n",
    "ax10 = fig.add_subplot(gs[1, 0]) # Merapi NDVI\n",
    "\n",
    "ax01 = fig.add_subplot(gs[0, 1]) # Merapi elevation\n",
    "ax11 = fig.add_subplot(gs[1, 1]) # Merapi slope\n",
    "ax02 = fig.add_subplot(gs[0, 2]) # Merapi shadow + overlay\n",
    "ax12 = fig.add_subplot(gs[1, 2]) # Merapi ifg\n",
    "ax03 = fig.add_subplot(gs[0, 3]) # range offset\n",
    "ax13 = fig.add_subplot(gs[1, 3]) # azimuth offset\n",
    "\n",
    "\n",
    "ax00.imshow(TRUE_COL,extent=TRUE_COL_extent)\n",
    "ax00_1 = inset_axes(ax00,width='50%',height='25%',loc=2)\n",
    "ax00_1.add_patch(Rectangle((90,-15),55,25,color='white'))\n",
    "world.plot(ax=ax00_1,color='lightgrey',edgecolor='black')\n",
    "ax00_1.scatter(110.4,-7.54,s=5,c='red')\n",
    "ax00_1.set_aspect('equal','box')\n",
    "ax00_1.set_xlim((90,145))\n",
    "ax00_1.set_ylim((-15,10))\n",
    "ax00_1.set_axis_off()\n",
    "\n",
    "ndvi_map = ax10.imshow(NDVI,cmap=ndvi_cmap,extent=NDVI_extent,vmin=-1,vmax=1)\n",
    "plt.colorbar(ndvi_map,label='NDVI [-]',orientation=orientation)\n",
    "\n",
    "dem_map = ax01.imshow(DEM_heights,cmap='gist_earth',extent=DEM_extent,vmin=0,vmax=3000)\n",
    "ax01.imshow(SHADING, cmap=cm.grayC, alpha=0.3 , extent=DEM_extent)\n",
    "plt.colorbar(dem_map,label='elevation [m]',orientation=orientation)\n",
    "\n",
    "slope_map = ax11.imshow(DEM_slope,cmap='Greys_r',extent=DEM_extent,vmin=0,vmax=45)\n",
    "plt.colorbar(slope_map,label='slope [deg.]', extend='max',orientation=orientation)\n",
    "\n",
    "ax02.imshow(ls_map,cmap='Greys',extent=DEM_extent)\n",
    "ax02.scatter([],[],s=30,c='black',edgecolor='black',label='Shadow')\n",
    "ax02.scatter([],[],s=30,c='white',edgecolor='black',label='Overlay')\n",
    "ax02.scatter([],[],s=30,c='grey',edgecolor='black',label='Normal or\\nforeshortening')\n",
    "ax02.legend(loc='best')\n",
    "\n",
    "ax12.imshow(IFG,extent=IFG_extent)\n",
    "\n",
    "\n",
    "# ax03.imshow(SHADING,cmap=cm.grayC,alpha=0.5, extent=DEM_extent)\n",
    "r_off_map = ax03.hexbin(obj.Lon_off.flatten(),obj.Lat_off.flatten(),C=obj.R_off.flatten(),gridsize=grid_size,cmap=cmap,vmin=clims[0],vmax=clims[1])\n",
    "plt.colorbar(r_off_map,label='range offset [m]',orientation=orientation)\n",
    "\n",
    "# ax13.imshow(SHADING,cmap=cm.grayC,alpha=0.5, extent=DEM_extent)\n",
    "a_off_map = ax13.hexbin(obj.Lon_off.flatten(),obj.Lat_off.flatten(),C=obj.A_off.flatten(),gridsize=grid_size,cmap=cmap,vmin=clims[0],vmax=clims[1])\n",
    "plt.colorbar(a_off_map,label='azimuth offset [m]',orientation=orientation)\n",
    "\n",
    "print(lon_lims,lat_lims)\n",
    "\n",
    "for (ax,text) in zip([ax00,ax10,ax01,ax11,ax02,ax12,ax03,ax13],['A','B','C','D','E','F','G','H']):\n",
    "    ax.add_artist(ScaleBar(sm.plot.get_1deg_dist(),location='upper right'))\n",
    "    if ax ==ax00:\n",
    "        ax.text(110.44570,-7.52014,text,fontsize=20,backgroundcolor=(1,1,1,0.3))\n",
    "    else:\n",
    "        ax.text(110.42633,-7.52014,text,fontsize=20,backgroundcolor=(1,1,1,0.3))\n",
    "    ax.set_xlim(lon_lims)\n",
    "    ax.set_ylim(lat_lims)\n",
    "    ax.set_axis_off()\n",
    "\n",
    "# fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.close('all')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pygmt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
